# -*- coding: utf-8 -*-
"""Flipkart Analysis using Python .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12vLmRf3zuxTwVPxrwH9mcTJcrdM3P1QS
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb
import warnings
warnings.filterwarnings('ignore')
from dateutil.relativedelta import relativedelta



df = pd.read_excel('/content/Flipkart_Product_Return_Sheet.xlsx')
df.head()

df.info()

"""## Null Values"""

df.isna().sum()

df['ReturnDate']=df['ReturnDate'].fillna(df['DeliveryDate'])
df['ReturnTime']=df['ReturnTime'].fillna(df['DeliveryTime'])

df['ReturnReason']=df['ReturnReason'].fillna('No Return')

"""## Duplicates"""

df.duplicated().sum()

"""## Feature Engineering"""

df=df[['OrderID','Return_Risk','OrderDate', 'OrderTime', 'DeliveryDate', 'DeliveryTime',
       'ReturnDate', 'ReturnTime', 'ReturnReason', 'Product_Name', 'Category','Company',
       'ProductPrice', 'Quantity', 'PaymentMethod', 'CustomerAge',
       'CustomerGender', 'City', 'State', 'CustomerPurchaseHistory',
       'CustomerReturnHistory', 'ProductRating', 'Product_Warranty',
       'ShippingMode', 'DiscountApplied']]

df['OrderDate']=pd.to_datetime(df['OrderDate'],format='%d-%m-%Y')
df['DeliveryDate']=pd.to_datetime(df['DeliveryDate'],format='%d-%m-%Y')

df['ReturnDate']=pd.to_datetime(df['ReturnDate'],format='%d-%m-%Y')

df['OrderDate']=pd.to_datetime(df['OrderDate'],format='%d-%m-%Y')
df['DeliveryDate']=pd.to_datetime(df['DeliveryDate'],format='%d-%m-%Y')

df['ReturnDate']=pd.to_datetime(df['ReturnDate'],format='%d-%m-%Y')

df['Return_Risk']=df['Return_Risk'].apply(lambda x:'Yes' if x==1 else 'No')

# Categorizing cities into tiers
city_tiers = {
    "Tier 1": ["Mumbai", "Delhi", "Bangalore", "Hyderabad", "Chennai", "Kolkata", "Pune", "Ahmedabad", "Surat"],
    "Tier 2": [
        "Jodhpur", "Visakhapatnam", "Raipur", "Agra", "Ludhiana", "Hubli", "Jaipur", "Madurai", "Tirupati",
        "Bhubaneswar", "Salem", "Patiala", "Aurangabad", "Kanpur", "Jalandhar", "Nashik", "Bhopal",
        "Ranchi", "Gurgaon", "Faridabad", "Lucknow", "Tiruchirappalli", "Kozhikode", "Thrissur", "Amritsar",
        "Vadodara", "Belgaum", "Guwahati", "Nagpur", "Gaya", "Patna", "Jabalpur", "Meerut", "Bilaspur",
        "Kollam", "Gwalior", "Udaipur", "Howrah", "Indore", "Warangal", "Cuttack", "Kota", "Mangalore",
        "Kochi", "Mysore", "Vijayawada", "Durg", "Coimbatore", "Varanasi", "Rajkot"
    ],
    "Tier 3": [
        "Muzaffarpur", "Nellore", "Korba", "Dibrugarh", "Nizamabad", "Bathinda", "Jorhat", "Rourkela",
        "Bhavnagar", "Siliguri", "Balasore", "Karnal", "Dhanbad", "Bhagalpur", "Bhilai", "Ajmer",
        "Sambalpur", "Ambala", "Darbhanga", "Jamshedpur", "Ujjain", "Karimnagar", "Hazaribagh",
        "Durgapur", "Thiruvananthapuram", "Khammam", "Asansol", "Panipat", "Tezpur", "Bokaro",
        "Guntur", "Silchar"
    ]
}

df['Tier']=np.where(df['City'].isin(city_tiers['Tier 1']),'Tier 1',
               np.where(df['City'].isin(city_tiers['Tier 2']),'Tier 2','Tier 3'))

delivery_delay=df['DeliveryDate']-df['OrderDate']
df['delivery_delay']=[ int(i.days) for i in  delivery_delay]

return_delay=df['ReturnDate']-df['DeliveryDate']
df['return_delay']=[ int(i.days) for i in  return_delay]

Sales=df['ProductPrice']*df['Quantity']*(1-df['DiscountApplied']/100)
df['Sales']= [round(i,2) for i in Sales]

# Combine Date and Time columns and convert to datetime
# Create a new column combining the date and time as strings
df['OrderDateTime'] = df['OrderDate'].astype(str) + ' ' + df['OrderTime'].astype(str)
df['DeliveryDateTime'] = df['DeliveryDate'].astype(str) + ' ' + df['DeliveryTime'].astype(str)
df['ReturnDateTime'] = df['ReturnDate'].astype(str) + ' ' + df['ReturnTime'].astype(str)

# Convert the new combined columns to datetime objects
df['OrderDateTime'] = pd.to_datetime(df['OrderDateTime'])
df['DeliveryDateTime'] = pd.to_datetime(df['DeliveryDateTime'])
df['ReturnDateTime'] = pd.to_datetime(df['ReturnDateTime'])
# Convert OrderTime to datetime before accessing hour
# Remove this line as it is causing the TypeError: df['OrderTime'] = pd.to_datetime(df['OrderTime'])

# Use the correctly created OrderDateTime for extracting features
df['Year']=df['OrderDateTime'].dt.year
df['Quarter']= [ f'Qtr {i}' for i in  df['OrderDateTime'].dt.quarter]
df['Month']=df['OrderDateTime'].dt.month_name()
df['Day']=df['OrderDateTime'].dt.day_name()
df['Hour']=df['OrderDateTime'].dt.hour # Extract hour from OrderDateTime
df['Quarter_N']=df['OrderDateTime'].dt.quarter
df['Month_N']=df['OrderDateTime'].dt.month
df['Day_N']=df['OrderDateTime'].dt.weekday
df['Hr_grp']=np.where(df['Hour'].between(6,11),'Morning',
                      np.where(df['Hour'].between(12,17),'Afternoon',
                               np.where(df['Hour'].between(18,22),'Evening','Night')))
df['Wk_Wn']=np.where(df['Day'].isin(['Saturday','Sunday']),'Weekend','Weekday')
df['Age_grp']=np.where(df['CustomerAge'].between(18,25),'18-25',
                       np.where(df['CustomerAge'].between(26,35),'26-35',
                           np.where(df['CustomerAge'].between(36,45),'36-45',
                                    np.where(df['CustomerAge'].between(46,60),'46-60','>60'))))

"""## TABULAR ANALYSIS

## A) Temporal & Delay Analysis
"""

# What is the average delivery delay and return delay per month

dd=df.groupby(['Month','Month_N'])[['delivery_delay']].mean().reset_index()
dd.sort_values(by='Month_N',ascending=True,inplace=True )
dd=dd[['Month','delivery_delay']]
dd['delivery_delay']= [ f'{round(i,2)} days' for i in dd['delivery_delay'] ]

rd=df.groupby(['Month','Month_N'])[['return_delay']].mean().reset_index()
rd.sort_values(by='Month_N',ascending=True,inplace=True )
rd=rd[['Month','return_delay']]
rd['return_delay']= [ f'{round(i,2)} days' for i in rd['return_delay'] ]

pd.merge(dd,rd,how='inner',on='Month' )

# How does delivery delay and  return delay vary across product categories

dd=df.groupby(['Category'])[['delivery_delay']].mean().reset_index()
dd.sort_values(by='Category',ascending=True,inplace=True )
dd['delivery_delay']= [ f'{round(i,2)} days' for i in dd['delivery_delay'] ]

rd=df.groupby(['Category'])[['return_delay']].mean().reset_index()
rd.sort_values(by='Category',ascending=True,inplace=True )
rd['return_delay']= [ f'{round(i,2)} days' for i in rd['return_delay'] ]

pd.merge(dd,rd,how='inner',on='Category' )

# Identify the top 5 Product with the highest return volumes , on last 6 months

df_w=df[df['return_delay']>0]
l_d= df_w['OrderDate'].max()
ls_d= l_d - relativedelta(months=6)

df_lm6 = df_w[df_w['OrderDate'].between(ls_d,l_d)]

df_g6= df_lm6.groupby(['Product_Name'])[['return_delay']].mean().reset_index()

df_g6['return_delay']= [ f'{round(i,2)} days ' for i in df_g6['return_delay'] ]
df_g6.sort_values(by='return_delay',ascending=False,inplace=True)

df_g6.head(10)

# Compare weekday vs weekend return rates, quarterwise

df_w=df[df['return_delay']>0]
df_w['W_dy_en']=np.where(df_w['Day'].isin(['Saturday','Sunday']),'Weekend','Weekday')

qt_d= pd.pivot_table(data=df_w,columns='W_dy_en',values='return_delay',index='Quarter').reset_index()
qt_d=qt_d[['Quarter','Weekend','Weekday']]
qt_d.columns.name=None
qt_d['Weekend']=[ f'{round(i,2)} days' for i in qt_d['Weekend'] ]
qt_d['Weekday']=[ f'{round(i,2)} days' for i in qt_d['Weekday'] ]

qt_d

# What is the  difference between order qty and return qty for product returns, productwise?

df_dl= df[df['return_delay']>0]

df_o=df.groupby('Product_Name')['OrderID'].count().reset_index()
df_o.columns=['Product_Name','Order']

df_r=df_dl.groupby('Product_Name')['OrderID'].count().reset_index()
df_r.columns=['Product_Name','Return']

pd.merge(df_o,df_r,how='inner',on='Product_Name' )

# Which Quarter sees the most returned orders product?

df_dl= df[df['return_delay']>0]

qt_p=pd.crosstab(index=df_dl['Product_Name'],columns=df_dl['Quarter']  ).reset_index()
qt_p.columns.name=None
qt_p

# Identify Top 5  months with the longest average delivery delays.

df_m= df.groupby(['Month'])['delivery_delay'].mean().reset_index()
df_m.sort_values('delivery_delay',inplace=True,ascending=False)
df_m['delivery_delay']=[ f'{round(i,2)} days' for i in df_m['delivery_delay'] ]

df_m.head(5)

# Which 20 city experiences the highest delivery delays

df_cs= df.groupby(['City','State'])['delivery_delay'].mean().reset_index()
df_cs.sort_values('delivery_delay',ascending=False,inplace=True)
df_cs['delivery_delay']=[ f'{round(i,2)} days' for i in  df_cs['delivery_delay'] ]

df_cs.head(20)

# Compare return frequency before and after Diwali and Navratri festivals , productwise with top 20.

df_mm=df[df['return_delay']>0]

df_mm['Major_Mn']=np.where(df_mm['Month'].isin(['October','November']),'Festival Month','Non Festival Month')

df_ma=df_mm[df_mm['Major_Mn']=='Festival Month']
df_nma=df_mm[df_mm['Major_Mn']=='Non Festival Month']

df_p_ma=df_ma.groupby('Product_Name')['OrderID'].count().reset_index()
df_p_nma=df_nma.groupby('Product_Name')['OrderID'].count().reset_index()

df_p_ma['%_Orders']=df_p_ma['OrderID']/df_p_ma['OrderID'].sum()*100
df_p_ma.columns=['Product_Name','Orders_Major','%_Orders_Major']

df_p_nma['%_Orders']=df_p_nma['OrderID']/df_p_nma['OrderID'].sum()*100
df_p_nma.columns=['Product_Name','Orders_Non_Major','%_Orders_Non_Major']

df_mami= pd.merge(df_p_ma,df_p_nma,on='Product_Name',how='inner')
df_mami.sort_values(by=['%_Orders_Major','%_Orders_Non_Major'],ascending=False,inplace=True)

df_mami.head(20)

# Find the distribution of return delays by tier , Categorywise.

df_mm=df[df['return_delay']>0]
df_pr_t= pd.pivot_table(data=df_mm,index='Category',columns='Tier',values='return_delay').reset_index()
df_pr_t.columns.name=None
df_pr_t['Tier 1']=[ f'{round(i,2)} days' for i in  df_pr_t['Tier 1'] ]
df_pr_t['Tier 2']=[ f'{round(i,2)} days' for i in  df_pr_t['Tier 2'] ]
df_pr_t['Tier 3']=[ f'{round(i,2)} days' for i in  df_pr_t['Tier 3'] ]
df_pr_t

#  Identify trends in delivery delays over the months, Tierwise.

df_m_tr= pd.pivot_table(data=df,index=['Month','Month_N'],columns='Tier',values='delivery_delay').reset_index()
df_m_tr.columns.name=None
df_m_tr.sort_values('Month_N',ascending=True,inplace=True)

df_m_tr=df_m_tr[['Month','Tier 1','Tier 2','Tier 3']]
df_m_tr['Tier 1']=[ f'{round(i,2)} days' for i in  df_m_tr['Tier 1'] ]
df_m_tr['Tier 2']=[ f'{round(i,2)} days' for i in  df_m_tr['Tier 2'] ]
df_m_tr['Tier 3']=[ f'{round(i,2)} days' for i in  df_m_tr['Tier 3'] ]

df_m_tr

"""## B) Customer Behavior & Segmentation"""

# What is the average return risk by age group , productwise

df_mm=df[df['return_delay']>0]

df_mm['Age_Prt']=np.where(df_mm['CustomerAge'].between(18,25),'18-25',
                       np.where(df_mm['CustomerAge'].between(26,35),'26-35',
                           np.where(df_mm['CustomerAge'].between(36,45),'36-45',
                                np.where(df_mm['CustomerAge'].between(46,60),'46-60','>60'))))

df_r_p= pd.pivot_table(data=df_mm,columns='Age_Prt',index='Product_Name',values='OrderID',aggfunc='count').reset_index()
df_r_p.columns.name=None
df_r_p

# Find top 15 products where female customers return  more frequently than males?

df_mm=df[df['return_delay']>0]

df_g_rr= pd.pivot_table(data=df_mm,index='Product_Name',columns='CustomerGender',values='OrderID',aggfunc='count').reset_index()
df_g_rr.columns.name=None

df_g_rr=df_g_rr[['Product_Name','Female','Male']]
df_g_rr['Diff']=df_g_rr['Female']-df_g_rr['Male']
df_g_rr.sort_values(by='Diff',ascending=False,inplace=True)
df_g_rr=df_g_rr[df_g_rr['Diff']>0]

df_g_rr.head(15)

# What is the average order value based on  age group

df_mm=df.copy()
df_mm['Age_Grp']=np.where(df_mm['CustomerAge'].between(18,25),'18-25',
                       np.where(df_mm['CustomerAge'].between(26,35),'26-35',
                           np.where(df_mm['CustomerAge'].between(36,45),'36-45',
                                np.where(df_mm['CustomerAge'].between(46,60),'46-60','>60'))))

df_a_o= df_mm.groupby('Age_Grp')[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_a_o['AOV']=df_a_o['Sales']/df_a_o['OrderID']
df_a_o['AOV']=[ round(i,2) for i in df_a_o['AOV']  ]
df_a_o

# Which 2 state has the highest return to order ratio and which is the lowest?

df_r=df[df['return_delay']>0]

df_or= df.groupby(by='State')['OrderID'].count().reset_index()
df_or.columns=['State','Orders']

df_rr=df_r.groupby(by='State')['OrderID'].count().reset_index()
df_rr.columns=['State','Returns']

df_o_r= pd.merge(df_or,df_rr,how='inner',on='State')
df_o_r['R:O']=df_o_r['Returns']/df_o_r['Orders']
df_o_r.sort_values(by='R:O',ascending=False,inplace=True)

df_or_1=df_o_r.head(2)
df_or_2=df_o_r.tail(2)
df_or_12= pd.concat((df_or_1,df_or_2))
df_or_12['H/L']=['High','Second High','Second Low','Low']

df_or_12

# How does customer purchase and return history correlate with delivery and  return delay?

df[['CustomerPurchaseHistory','CustomerReturnHistory','delivery_delay','return_delay']].corr()

# Group customers by Tier and analyze average order value and average return value

df_r=df[df['return_delay']>0]

df_or= df.groupby(by='Tier')[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_or.columns=['Tier','Orders','Sales']
df_or['AOV']=df_or['Sales']/df_or['Orders']
df_or['AOV']=[ round(i,2) for i in df_or['AOV']  ]

df_rr= df_r.groupby(by='Tier')[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_rr.columns=['Tier','Return','Loss']
df_rr['ARV']=df_rr['Loss']/df_rr['Return']
df_rr['ARV']=[ round(i,2) for i in df_rr['ARV']  ]

pd.merge(df_or,df_rr,how='inner',on='Tier')

# What’s the top  20 city with the most loyal customers (lowest return percentage)

df_r=df[df['return_delay']>0]

df_or= df.groupby(by='City')['OrderID'].count().reset_index()
df_or.columns=['City','Orders']

df_rr=df_r.groupby(by='City')['OrderID'].count().reset_index()
df_rr.columns=['City','Returns']

df_o_r= pd.merge(df_or,df_rr,how='inner',on='City')
df_o_r['%_Return']=df_o_r['Returns']/df_o_r['Orders']*100
df_o_r['%_Return']=[ round(i,2) for i in df_o_r['%_Return'] ]
df_o_r.sort_values(by='%_Return',inplace=True)

df_o_r.head(20)

# Compare average purchase history between returners and non-returners, statewise

df_r=df[df['return_delay']>0]
df_nr=df[df['return_delay']==0]

rr= df_r.groupby('State')['CustomerPurchaseHistory'].mean().reset_index()
rr.columns=['State','Return_P_History']
rr['Return_P_History']=[ round(i,2) for i in rr['Return_P_History']]

nr= df_nr.groupby('State')['CustomerPurchaseHistory'].mean().reset_index()
nr.columns=['State','Non_Return_P_History']
nr['Non_Return_P_History']=[ round(i,2) for i in nr['Non_Return_P_History']]

pd.merge(rr,nr,on='State',how='inner')

# What is the return percentage by age segment (e.g., <25, 25–40, >40), Quarterwise

df_mm=df.copy()
df_mm['Age_Grp']=np.where(df_mm['CustomerAge'].between(18,25),'18-25',
                       np.where(df_mm['CustomerAge'].between(26,35),'26-35',
                           np.where(df_mm['CustomerAge'].between(36,45),'36-45',
                                np.where(df_mm['CustomerAge'].between(46,60),'46-60','>60'))))

df_r=df_mm[df_mm['return_delay']>0]

df_or= pd.pivot_table(data=df_mm,columns='Quarter',index='Age_Grp',values='OrderID',aggfunc='count').reset_index()
df_or.columns.name=None
df_or.columns=['Age_Grp','Order Q1','Order Q2','Order Q3','Order Q4']

df_rr= pd.pivot_table(data=df_r,columns='Quarter',index='Age_Grp',values='OrderID',aggfunc='count').reset_index()
df_rr.columns.name=None
df_rr.columns=['Age_Grp','Return Q1','Return Q2','Return Q3','Return Q4']

df_o_r= pd.merge(df_or,df_rr,how='inner',on='Age_Grp')
df_o_r['% Return Q1']=df_o_r['Return Q1']/df_o_r['Order Q1']*100
df_o_r['% Return Q1']=[ f'{round(i,2)} %' for i in   df_o_r['% Return Q1']]

df_o_r['% Return Q2']=df_o_r['Return Q2']/df_o_r['Order Q2']*100
df_o_r['% Return Q2']=[ f'{round(i,2)} %' for i in   df_o_r['% Return Q2']]

df_o_r['% Return Q3']=df_o_r['Return Q3']/df_o_r['Order Q3']*100
df_o_r['% Return Q3']=[ f'{round(i,2)} %' for i in   df_o_r['% Return Q3']]

df_o_r['% Return Q4']=df_o_r['Return Q4']/df_o_r['Order Q4']*100
df_o_r['% Return Q4']=[ f'{round(i,2)} %' for i in   df_o_r['% Return Q4']]

df_or_pt=df_o_r[['Age_Grp','% Return Q1','% Return Q2','% Return Q3','% Return Q4' ]]
df_or_pt

# Which states have customers with the highest order frequency, Genderwise

df_g_s= pd.pivot_table(data=df,columns='CustomerGender',index='State',values='OrderID',aggfunc='count').reset_index()
df_g_s.columns.name=None
df_g_s

# Create a heatmap of return percentage by gender and product.

df_r=df[df['return_delay']>0]

df_or= pd.pivot_table(data=df,columns='CustomerGender',index='Product_Name',values='OrderID',aggfunc='count').reset_index()
df_or.columns.name=None
df_or.columns=[ 'Product_Name','Female_O','Male_O','Other_O' ]

df_rr= pd.pivot_table(data=df_r,columns='CustomerGender',index='Product_Name',values='OrderID',aggfunc='count').reset_index()
df_rr.columns.name=None
df_rr.columns=[ 'Product_Name','Female_R','Male_R','Other_R' ]

df_o_r=pd.merge(df_or,df_rr,how='inner',on='Product_Name')
df_o_r['Female_R_%']=df_o_r['Female_R']/df_o_r['Female_O']*100
df_o_r['Male_R_%']=df_o_r['Male_R']/df_o_r['Male_O']*100
df_o_r['Other_R_%']=df_o_r['Other_R']/df_o_r['Other_O']*100

df_o_r['Female_R_%']=[ f'{round(i,2)} %' for i in   df_o_r['Female_R_%']]
df_o_r['Male_R_%']=[ f'{round(i,2)} %' for i in   df_o_r['Male_R_%']]
df_o_r['Other_R_%']=[ f'{round(i,2)} %' for i in   df_o_r['Other_R_%']]

df_o_r=df_o_r[['Product_Name','Female_R_%','Male_R_%','Other_R_%' ]]

df_o_r

# Identify state with high avg return history  and state with low avg purchase history, quarterwise

df_rh= pd.pivot_table(data=df,index='State',columns='Quarter',values='CustomerReturnHistory',aggfunc='sum' ).reset_index()
df_rh.columns.name=None
df_rh['Avg_Return']=(df_rh['Qtr 1']+df_rh['Qtr 2']+df_rh['Qtr 3']+df_rh['Qtr 4'])/4
df_rh.sort_values(by='Avg_Return',ascending=False,inplace=True)

df_ph= pd.pivot_table(data=df,index='State',columns='Quarter',values='CustomerPurchaseHistory',aggfunc='sum' ).reset_index()
df_ph.columns.name=None
df_ph['Avg_Purchase']=(df_ph['Qtr 1']+df_ph['Qtr 2']+df_ph['Qtr 3']+df_ph['Qtr 4'])/4
df_ph.sort_values(by='Avg_Purchase',ascending=True,inplace=True)

print('Return History: \n',df_rh )
print('\n')
print('Purchase History: \n',df_ph )

#  Segment by payment method and compare orders,avg_amount, purchase and return behaviors.

df_o= df.groupby('PaymentMethod')['OrderID'].count().reset_index()
df_o.columns=['PaymentMethod','Orders']

df_a= df.groupby('PaymentMethod')['Sales'].mean().reset_index()
df_a.columns=['PaymentMethod','Avg_Amount']
df_a['Avg_Amount']=[ round(i,2) for i in df_a['Avg_Amount']  ]

df_ph= df.groupby('PaymentMethod')['CustomerPurchaseHistory'].sum().reset_index()
df_ph.columns=['PaymentMethod','Purchase History']

df_rh= df.groupby('PaymentMethod')['CustomerReturnHistory'].sum().reset_index()
df_rh.columns=['PaymentMethod','Return History']

pd.merge(pd.merge(df_o,df_a,how='inner',on='PaymentMethod'),
         pd.merge(df_ph,df_rh,how='inner',on='PaymentMethod'),on='PaymentMethod',how='inner')

# Which age group buys the most  products on average based on orders and which the lowest, also find its quantity  and sales  ?

df_mm=df.copy()
df_mm['Age_Grp']=np.where(df_mm['CustomerAge'].between(18,25),'18-25',
                       np.where(df_mm['CustomerAge'].between(26,35),'26-35',
                           np.where(df_mm['CustomerAge'].between(36,45),'36-45',
                                np.where(df_mm['CustomerAge'].between(46,60),'46-60','>60'))))


grp_h= df_mm.groupby(['Age_Grp','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
grp_h.columns=['Age_Grp', 'Product_Name', 'Orders', 'Quantity', 'Sales']
grp_h['Rank']=grp_h.groupby(['Age_Grp'])['Orders'].rank(method='dense',ascending=False)
grp_h=grp_h[grp_h['Rank']==1]
grp_h['Sales']=  [f'{i} M' for i in  np.round( grp_h['Sales']/1000000,2)]

grp_l= df_mm.groupby(['Age_Grp','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
grp_l.columns=['Age_Grp', 'Product_Name', 'Orders', 'Quantity', 'Sales']
grp_l['Rank']=grp_l.groupby(['Age_Grp'])['Orders'].rank(method='dense',ascending=True)
grp_l=grp_l[grp_l['Rank']==1]
grp_l['Sales']=  [f'{i} M' for i in  np.round( grp_l['Sales']/1000000,2)]

pd.concat([grp_h,grp_l]).sort_values('Age_Grp')[['Age_Grp', 'Product_Name', 'Orders', 'Quantity', 'Sales']].set_index(['Age_Grp', 'Product_Name'])

# Is there a significant difference in purchase behavior between genders , statewise

df_f=df[df['CustomerGender']=='Female']
df_m=df[df['CustomerGender']=='Male']
df_o=df[df['CustomerGender']=='Other']

f_df= df_f.groupby('State')[['CustomerPurchaseHistory', 'CustomerReturnHistory']].sum().reset_index()
f_df.columns=['State','Purchase History (Female)','Return History (Female)' ]
f_df['Purchase History (Female)']=[ round(i,2) for i in f_df['Purchase History (Female)']  ]
f_df['Return History (Female)']=[ round(i,2) for i in f_df['Return History (Female)']  ]

m_df= df_m.groupby('State')[['CustomerPurchaseHistory', 'CustomerReturnHistory']].sum().reset_index()
m_df.columns=['State','Purchase History (Male)','Return History (Male)' ]
m_df['Purchase History (Male)']=[ round(i,2) for i in m_df['Purchase History (Male)']  ]
m_df['Return History (Male)']=[ round(i,2) for i in m_df['Return History (Male)']  ]

o_df= df_o.groupby('State')[['CustomerPurchaseHistory', 'CustomerReturnHistory']].sum().reset_index()
o_df.columns=['State','Purchase History (Other)','Return History (Other)' ]
o_df['Purchase History (Other)']=[ round(i,2) for i in o_df['Purchase History (Other)']  ]
o_df['Return History (Other)']=[ round(i,2) for i in o_df['Return History (Other)']  ]


fmo=pd.merge(pd.merge(m_df,f_df,on='State',how='inner'),o_df,on='State',how='inner')
fmo['Total Purchase History']=fmo['Purchase History (Female)']+fmo['Purchase History (Male)']+fmo['Purchase History (Other)']
fmo['Total Return History']=fmo['Return History (Female)']+fmo['Return History (Male)']+fmo['Return History (Other)']

fmo

# What percentage of returns comparing with previous month  comes from Tier 1 , Tier 2 and Tier 3 cities

df_rt=df[df['return_delay']>0]

df_t1=df_rt[df_rt['Tier']=='Tier 1']
df_t2=df_rt[df_rt['Tier']=='Tier 2']
df_t3=df_rt[df_rt['Tier']=='Tier 3']

t1_df=df_t1.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
t1_df=t1_df[['Month','OrderID']]
t1_df.columns=['Month','Order T1er1']
t1_df['Previous Order T1er1']=t1_df['Order T1er1'].shift(1).fillna(0)
t1_df['% Order Tier1']= (t1_df['Order T1er1']-t1_df['Previous Order T1er1'])/t1_df['Previous Order T1er1']*100
t1_df['% Order Tier1']= [ f'{round(i,2)} %' for i in  t1_df['% Order Tier1'] ]
t1_df['% Order Tier1']= np.where( t1_df['% Order Tier1']=='inf %', f'0.00 %', t1_df['% Order Tier1'])

t2_df=df_t2.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
t2_df=t2_df[['Month','OrderID']]
t2_df.columns=['Month','Order T1er2']
t2_df['Previous Order T1er2']=t2_df['Order T1er2'].shift(1).fillna(0)
t2_df['% Order Tier2']= (t2_df['Order T1er2']-t2_df['Previous Order T1er2'])/t2_df['Previous Order T1er2']*100
t2_df['% Order Tier2']= [ f'{round(i,2)} %' for i in  t2_df['% Order Tier2'] ]
t2_df['% Order Tier2']= np.where( t2_df['% Order Tier2']=='inf %', f'0.00 %', t2_df['% Order Tier2'])

t3_df=df_t3.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
t23df=t3_df[['Month','OrderID']]
t3_df.columns=['Month','Order T1er3']
t3_df['Previous Order T1er3']=t3_df['Order T1er3'].shift(1).fillna(0)
t3_df['% Order Tier3']= (t3_df['Order T1er3']-t3_df['Previous Order T1er3'])/t3_df['Previous Order T1er3']*100
t3_df['% Order Tier3']= [ f'{round(i,2)} %' for i in  t3_df['% Order Tier3'] ]
t3_df['% Order Tier3']= np.where( t3_df['% Order Tier3']=='inf %', f'0.00 %', t3_df['% Order Tier3'])

tr_123 =pd.merge(pd.merge(t1_df,t2_df,how='inner',on='Month'),t3_df,how='inner',on='Month')
tr_123

#  Identify top 5 city  contributing to 80% of returns , Quarterwise , along with its revenue loss .

df_rt=df[df['return_delay']>0]

df_q1=df_rt[df_rt['Quarter']=='Qtr 1']
df_q2=df_rt[df_rt['Quarter']=='Qtr 2']
df_q3=df_rt[df_rt['Quarter']=='Qtr 3']
df_q4=df_rt[df_rt['Quarter']=='Qtr 4']

q1_df= df_q1.groupby('State')['OrderID'].count().reset_index()
q1_df.columns=['State','Orders Qtr 1']
q1_df_s=df_q1.groupby('State')['Sales'].sum().reset_index()
q1_df_s.columns=['State','Loss Qtr 1']
q1_df_s['Loss Qtr 1']=[ f'{round(i/(10**6),2)} M' for i in q1_df_s['Loss Qtr 1']]
q1_df_f= q1_df.merge(q1_df_s,on='State',how='inner')
q1_df_f.sort_values(by='Loss Qtr 1',ascending=False,inplace=True)

q2_df= df_q2.groupby('State')['OrderID'].count().reset_index()
q2_df.columns=['State','Orders Qtr 2']
q2_df_s=df_q2.groupby('State')['Sales'].sum().reset_index()
q2_df_s.columns=['State','Loss Qtr 2']
q2_df_s['Loss Qtr 2']=[ f'{round(i/(10**6),2)} M' for i in q2_df_s['Loss Qtr 2']]
q2_df_f= q2_df.merge(q2_df_s,on='State',how='inner')
q2_df_f.sort_values(by='Loss Qtr 2',ascending=False,inplace=True)

q3_df= df_q3.groupby('State')['OrderID'].count().reset_index()
q3_df.columns=['State','Orders Qtr 3']
q3_df_s=df_q3.groupby('State')['Sales'].sum().reset_index()
q3_df_s.columns=['State','Loss Qtr 3']
q3_df_s['Loss Qtr 3']=[ f'{round(i/(10**6),2)} M' for i in q3_df_s['Loss Qtr 3']]
q3_df_f= q3_df.merge(q3_df_s,on='State',how='inner')
q3_df_f.sort_values(by='Loss Qtr 3',ascending=False,inplace=True)

q4_df= df_q4.groupby('State')['OrderID'].count().reset_index()
q4_df.columns=['State','Orders Qtr 4']
q4_df_s=df_q4.groupby('State')['Sales'].sum().reset_index()
q4_df_s.columns=['State','Loss Qtr 4']
q4_df_s['Loss Qtr 4']=[ f'{round(i/(10**6),2)} M' for i in q4_df_s['Loss Qtr 4']]
q4_df_f= q4_df.merge(q4_df_s,on='State',how='inner')
q4_df_f.sort_values(by='Loss Qtr 4',ascending=False,inplace=True)


q_1234= pd.merge(pd.merge(q1_df_f,q2_df_f,how='inner',on='State'),pd.merge(q3_df_f,q4_df_f,how='inner',on='State'),how='inner',on='State')
q_1234.head(5)

# Analyze return behavior based on shipping mode preference statewise

df_rt=df[df['return_delay']>0]

df_st=df_rt[df_rt['ShippingMode']=='Standard']
df_ex=df_rt[df_rt['ShippingMode']=='Express']

sr_df= df_st.groupby(['Month','Month_N'])['OrderID'].count().reset_index()
sr_df.columns=['Month','MN','Orders Standard Shipmode']
sr_df.sort_values(by='MN',inplace=True)
sr_df=sr_df[['Month','Orders Standard Shipmode']]

ex_df= df_ex.groupby(['Month','Month_N'])['OrderID'].count().reset_index()
ex_df.columns=['Month','MN','Orders Standard Xpressmo']
ex_df.sort_values(by='MN',inplace=True)
ex_df=ex_df[['Month','Orders Standard Xpressmo']]

sr_df.merge(ex_df,how='inner',on='Month')

# Analyze return behavior, and overall retuens handle(return history) based on shipping mode preference, statewise

df_rt=df[df['return_delay']>0]

df_e=df[df['ShippingMode']=='Express']
df_s=df[df['ShippingMode']=='Standard']

df_e_rt=df_rt[df_rt['ShippingMode']=='Express']
df_s_rt=df_rt[df_rt['ShippingMode']=='Standard']

df_exp_rh= df_e.groupby(['State'])['CustomerReturnHistory'].sum().reset_index()
df_exp_rh.columns=['state','Return_History_Exp']

df_st_rh= df_s.groupby(['State'])['CustomerReturnHistory'].sum().reset_index()
df_st_rh.columns=['state','Return_History_St']

df_exp_rh_rt= df_e_rt.groupby(['State'])['OrderID'].count().reset_index()
df_exp_rh_rt.columns=['state','Return_Exp']

df_st_rh_rt= df_s_rt.groupby(['State'])['OrderID'].count().reset_index()
df_st_rh_rt.columns=['state','Return_St']

pd.merge(pd.merge(df_exp_rh,df_exp_rh_rt,how='left',on='state'),pd.merge(df_st_rh,df_st_rh_rt,how='left',on='state'),how='inner',on='state')

# What’s the average sales per customer by age group, Monthwise

df_mm=df.copy()
df_mm['Age_Grp']=np.where(df_mm['CustomerAge'].between(18,25),'18-25',
                       np.where(df_mm['CustomerAge'].between(26,35),'26-35',
                           np.where(df_mm['CustomerAge'].between(36,45),'36-45',
                                np.where(df_mm['CustomerAge'].between(46,60),'46-60','>60'))))


df_18_25=df_mm[df_mm['Age_Grp']=='18-25'].groupby(['Month','Month_N'])['Sales'].mean().reset_index()
df_18_25.sort_values('Month_N',inplace=True)
df_18_25=df_18_25[['Month','Sales']]
df_18_25['Sales']= [ round(i,2) for i in  df_18_25['Sales']   ]
df_18_25.columns=['Month','Sales_18_25']

df_26_35=df_mm[df_mm['Age_Grp']=='26-35'].groupby(['Month','Month_N'])['Sales'].mean().reset_index()
df_26_35.sort_values('Month_N',inplace=True)
df_26_35=df_26_35[['Month','Sales']]
df_26_35['Sales']= [ round(i,2) for i in  df_26_35['Sales']   ]
df_26_35.columns=['Month','Sales_26_35']

df_36_45=df_mm[df_mm['Age_Grp']=='36-45'].groupby(['Month','Month_N'])['Sales'].mean().reset_index()
df_36_45.sort_values('Month_N',inplace=True)
df_36_45=df_36_45[['Month','Sales']]
df_36_45['Sales']= [ round(i,2) for i in  df_36_45['Sales']   ]
df_36_45.columns=['Month','Sales_36_45']

df_46_60=df_mm[df_mm['Age_Grp']=='46-60'].groupby(['Month','Month_N'])['Sales'].mean().reset_index()
df_46_60.sort_values('Month_N',inplace=True)
df_46_60=df_46_60[['Month','Sales']]
df_46_60['Sales']= [ round(i,2) for i in  df_46_60['Sales']   ]
df_46_60.columns=['Month','Sales_46_60']

df_60_a=df_mm[df_mm['Age_Grp']=='>60'].groupby(['Month','Month_N'])['Sales'].mean().reset_index()
df_60_a.sort_values('Month_N',inplace=True)
df_60_a=df_60_a[['Month','Sales']]
df_60_a['Sales']= [ round(i,2) for i in  df_60_a['Sales']   ]
df_60_a.columns=['Month','Sales_>60']


pd.merge(pd.merge(pd.merge(df_18_25,df_26_35,how='inner',on='Month'),
                  pd.merge(df_36_45,df_46_60,how='inner',on='Month') ,
                  how='inner',on='Month'),df_60_a,how='inner',on='Month')

# Which top 20  city have high purchase frequency but low return percentage, both history and today

df_rt=df[df['return_delay']>0]

ord= df.groupby('City')['OrderID'].count().reset_index()
ord.columns=['City','Orders']
ord['Freq']= ord['Orders']/ord['Orders'].sum()*100
ord['Freq']= [ round(i,3) for i in ord['Freq'] ]

ord_rt= df_rt.groupby('City')['OrderID'].count().reset_index()
ord_rt.columns=['City','Returns']
ord_rt['R_Freq']= ord_rt['Returns']/ord_rt['Returns'].sum()*100
ord_rt['R_Freq']= [ round(i,3) for i in ord_rt['R_Freq'] ]

or_rt= pd.merge(ord,ord_rt,how='left',on='City' )
or_rt=or_rt[['City','Freq','R_Freq']]


ord_h= df.groupby('City')['CustomerPurchaseHistory'].sum().reset_index()
ord_h.columns=['City','Orders_History']
ord_h['Freq_H']= ord_h['Orders_History']/ord_h['Orders_History'].sum()*100
ord_h['Freq_H']= [ round(i,3) for i in ord_h['Freq_H'] ]

ord_rt_h= df.groupby('City')['CustomerReturnHistory'].sum().reset_index()
ord_rt_h.columns=['City','Return_History']
ord_rt_h['Freq_Rt_H']= ord_rt_h['Return_History']/ord_rt_h['Return_History'].sum()*100
ord_rt_h['Freq_Rt_H']= [ round(i,3) for i in ord_rt_h['Freq_Rt_H'] ]

or_rt_h= pd.merge(ord_h,ord_rt_h,how='left',on='City' )
or_rt_h=or_rt_h[['City','Freq_H','Freq_Rt_H']]

rt_hr= pd.merge(or_rt,or_rt_h,on='City',how='inner')
rt_hr.sort_values(by=[ 'Freq', 'R_Freq', 'Freq_H', 'Freq_Rt_H'] , ascending=[False,True,False,True], inplace=True)
rt_hr.head(20)

"""## C) Product Analysis"""

# Which quarter  has the highest rating , along with its sales , product category wise , along with its lowest

df_ct_qt= df.groupby(['Category','Quarter'])[['ProductRating','OrderID','Quantity','Sales']].agg({'ProductRating':'mean',
                                                                                        'OrderID':'count' ,'Quantity':'sum','Sales':'sum'}).reset_index()
df_ct_qt.columns=['Category', 'Quarter', 'Rating', 'Orders', 'Quantity', 'Sales']

df_ct_qt['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_ct_qt['Sales']]
df_ct_qt['Rating']=  [  round(i,2) for i in   df_ct_qt['Rating'] ]
df_ct_qt2=df_ct_qt.copy()

df_ct_qt['Rank']= df_ct_qt.groupby('Category')['Orders'].rank(method='dense',ascending=False)
df_ct_qt= df_ct_qt[df_ct_qt['Rank']==1]
df_ct_qt=df_ct_qt[['Category', 'Quarter', 'Rating', 'Orders', 'Quantity', 'Sales']]

df_ct_qt2['Rank']= df_ct_qt2.groupby('Category')['Orders'].rank(method='dense',ascending=True)
df_ct_qt2= df_ct_qt2[df_ct_qt2['Rank']==1]
df_ct_qt2=df_ct_qt2[['Category', 'Quarter', 'Rating', 'Orders', 'Quantity', 'Sales']]

pd.concat((df_ct_qt,df_ct_qt2)).sort_values(['Category','Orders'],ascending=False).set_index(['Category', 'Quarter'])

# What are the most and the least returned products by name, how many times returned and its return history , based on category

df_rt=df[df['return_delay']>0]

df_ct_p_rt=df_rt.groupby(['Category','Product_Name'])['OrderID'].count().reset_index()
df_ct_p_rt.columns=['Category',	'Product_Name',	'Orders']
df_ct_p_rt_l=df_rt.groupby(['Category','Product_Name'])['Sales'].sum().reset_index()
df_ct_p_rt_l.columns=['Category',	'Product_Name',	'Loss']
df_ct_p= df.groupby(['Category','Product_Name'])['CustomerReturnHistory'].sum().reset_index()
df_ct_p.columns=['Category','Product_Name',	'Return_History']

rt_hr= pd.merge(pd.merge(df_ct_p_rt,df_ct_p,on=['Category','Product_Name'],how='right'),df_ct_p_rt_l,on=['Category','Product_Name'],how='left')
rt_hr['Rank'] =rt_hr.groupby('Category')['Orders'].rank(method='dense',ascending=False)
rt_hr=rt_hr[rt_hr['Rank']==1]
rt_hr=rt_hr[['Category', 'Product_Name', 'Orders', 'Return_History','Loss']]
rt_hr['Loss']=[  f'{round(i/1000000,2)} M'  for i in rt_hr['Loss'] ]

rt_hr2= pd.merge(pd.merge(df_ct_p_rt,df_ct_p,on=['Category','Product_Name'],how='right'),df_ct_p_rt_l,on=['Category','Product_Name'],how='left')
rt_hr2['Rank'] =rt_hr2.groupby('Category')['Orders'].rank(method='dense',ascending=True)
rt_hr2=rt_hr2[rt_hr2['Rank']==1]
rt_hr2=rt_hr2[['Category', 'Product_Name', 'Orders', 'Return_History','Loss']]
rt_hr2['Loss']=[  f'{round(i/1000000,2)} M'  for i in rt_hr2['Loss'] ]

pd.concat((rt_hr,rt_hr2)).sort_values(['Category','Orders'],ascending=False).set_index(['Category', 'Product_Name'])

# Analyze product return reasons by Category, based on return

df_rt=df[df['return_delay']>0]

df_r=df_rt.groupby(['Product_Name','ReturnReason'])['OrderID'].count().reset_index()
df_r.columns=['Product_Name','Reason',	'Return']

df_r_h= df.groupby(['Product_Name','ReturnReason'])['CustomerReturnHistory'].sum().reset_index()
df_r_h.columns=['Product_Name','Reason',	'Return_History']

df_rt_rh= pd.merge(df_r,df_r_h,on=['Product_Name','Reason'],how='right')
df_rt_rh['Return']=df_rt_rh['Return'].fillna(0)
df_rt_rh['Rank']= df_rt_rh.groupby('Product_Name')['Return'].rank(method='dense',ascending=False)
df_rt_rh= df_rt_rh[df_rt_rh['Rank']==1]

df_rt_rh=df_rt_rh[['Product_Name', 'Reason', 'Return', 'Return_History']]
df_rt_rh

# Identify top 20 products with low ratings but high return volume.

df_rt=df[df['return_delay']>0]

df_prt= df.groupby('Product_Name')['ProductRating'].mean().reset_index()
df_prt['ProductRating']= [ round(i,2) for i in  df_prt['ProductRating']  ]

df_rt_v= df_rt.groupby('Product_Name')['Quantity'].sum().reset_index()

rt_vl= pd.merge(df_prt,df_rt_v,how='left',on='Product_Name')
rt_vl.sort_values(by=['ProductRating','Quantity'],ascending=[True,False],inplace=True)

rt_vl.head(20)

# Compare product categories by orders, qty , sales, orders_return, qty_return, loss

df_rt=df[df['return_delay']>0]

df_sl= df.groupby('Category')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
df_sl['Sales']=[  round(i,2)  for i in df_sl['Sales'] ]
df_sl.columns=['Category','Orders',	'Quantity',	'Sales']
df_sl['Sales']=[ f'{round(i/1000000000,2)} B'  for i in df_sl['Sales'] ]

df_sl_rt=df_rt.groupby('Category')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
df_sl_rt['Sales']=[  round(i,2)  for i in df_sl_rt['Sales'] ]
df_sl_rt.columns=['Category','Returns',	'Quantity_Return','Loss']
df_sl_rt['Loss']=[ f'{round(i/1000000000,2)} B'  for i in df_sl_rt['Loss'] ]

pd.merge(df_sl,df_sl_rt,on='Category',how='left')

# Detect seasonal  performance , statewise .

seasons = {"March": "Spring","April": "Spring","May": "Summer", "June": "Summer","July": "Summer", "August": "Rainy","September": "Rainy",
            "October": "Autumn",  "November": "Autumn", "December": "Winter", "January": "Winter", "February": "Winter"}
df_mm=df.copy()
df_mm['Seasons']= df_mm['Month'].replace(seasons)

df_mm_a= df_mm[df_mm['Seasons']=='Autumn']
df_mm_r= df_mm[df_mm['Seasons']=='Rainy']
df_mm_sp= df_mm[df_mm['Seasons']=='Spring']
df_mm_sm= df_mm[df_mm['Seasons']=='Summer']
df_mm_w= df_mm[df_mm['Seasons']=='Winter']

a_df=df_mm_a.groupby('State')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
a_df.columns=['State', 'Order_Autumn', 'Quantity_Autumn', 'Sales_Autumn']

r_df= df_mm_r.groupby('State')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
r_df.columns=['State', 'Order_Rainy', 'Quantity_Rainy', 'Sales_Rainy']

sp_df=df_mm_sp.groupby('State')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
sp_df.columns=['State', 'Order_Spring', 'Quantity_Spring', 'Sales_Spring']

sm_df=df_mm_sm.groupby('State')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
sm_df.columns=['State', 'Order_Summer', 'Quantity_Summer', 'Sales_Summer']

w_df=df_mm_w.groupby('State')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
w_df.columns=['State', 'Order_Winter', 'Quantity_Winter', 'Sales_Winter']


pd.merge(pd.merge(pd.merge(sm_df,r_df,on='State',how='inner'),
          pd.merge(a_df,w_df,on='State',how='inner'),on='State',how='inner'),sp_df,on='State',how='inner')

# Detect best product performance seasonwise, based on total orders, qty and sales

seasons = {"March": "Spring","April": "Spring","May": "Summer", "June": "Summer","July": "Summer", "August": "Rainy","September": "Rainy",
            "October": "Autumn",  "November": "Autumn", "December": "Winter", "January": "Winter", "February": "Winter"}
df_mm=df.copy()
df_mm['Seasons']= df_mm['Month'].replace(seasons)

df_s_sl=df_mm.groupby(['Seasons','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
df_s_sl['Rank']= df_s_sl.groupby('Seasons')['OrderID'].rank(method='dense',ascending=False)
df_s_sl= df_s_sl[df_s_sl['Rank']==1]
df_s_sl.columns=['Seasons',	'Product_Name',	'Orders',	'Quantity',	'Sales',	'Rank']
df_s_sl=df_s_sl[['Seasons',	'Product_Name',	'Orders',	'Quantity',	'Sales']]
df_s_sl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_s_sl['Sales'] ]

df_s_sl2=df_mm.groupby(['Seasons','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()
df_s_sl2['Rank']= df_s_sl2.groupby('Seasons')['OrderID'].rank(method='dense',ascending=True)
df_s_sl2= df_s_sl2[df_s_sl2['Rank']==1]
df_s_sl2.columns=['Seasons',	'Product_Name',	'Orders',	'Quantity',	'Sales',	'Rank']
df_s_sl2=df_s_sl2[['Seasons',	'Product_Name',	'Orders',	'Quantity',	'Sales']]
df_s_sl2['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_s_sl2['Sales'] ]

pd.concat((df_s_sl,df_s_sl2)).sort_values(['Seasons','Orders'],ascending=False  ).set_index(['Seasons',	'Product_Name'])

# Identify the most and least soldable product in each state, based on Return/Order ratio (high ratio, less soldable and vice versa ).

df_rt=df[df['return_delay']>0]

df_ord= df.groupby(['State','Product_Name'])['OrderID'].count().reset_index()
df_ord.columns=['State','Product','Orders']

df_rtr= df_rt.groupby(['State','Product_Name'])['OrderID'].count().reset_index()
df_rtr.columns=['State','Product','Return']

od_rt= pd.merge(df_ord,df_rtr,how='inner',on=['State','Product'])
od_rt['R/O Ratio']= od_rt['Return']/od_rt['Orders']
od_rt['R/O Ratio']=[ round(i,3) for i in od_rt['R/O Ratio']  ]
od_rt['Rank']=od_rt.groupby('State')['R/O Ratio'].rank(method='dense',ascending=True)
od_rt=od_rt[od_rt['Rank']==1]

od_rt2= pd.merge(df_ord,df_rtr,how='inner',on=['State','Product'])
od_rt2['R/O Ratio']= od_rt2['Return']/od_rt2['Orders']
od_rt2['R/O Ratio']=[ round(i,3) for i in od_rt2['R/O Ratio']  ]
od_rt2['Rank']=od_rt2.groupby('State')['R/O Ratio'].rank(method='dense',ascending=False)
od_rt2=od_rt2[od_rt2['Rank']==1]

pd.concat((od_rt,od_rt2)).sort_values(['State','R/O Ratio'],ascending=False )[['State',	'Product',	'Orders',
                                                                               'Return',	'R/O Ratio']].set_index(['State',	'Product'])

# Identify city with highest and lowest average delivery delay, categories , also find its orders, sales, purchase history

df_dl= df.groupby(['Category','City'])[['delivery_delay','OrderID','Sales',
                                 'CustomerPurchaseHistory']].agg({'delivery_delay':'mean','OrderID':'count',
                                                                  'Sales':'sum','CustomerPurchaseHistory':'sum'}).reset_index()
df_dl['delivery_delay']=[ round(i,2) for i in  df_dl['delivery_delay']]
df_dl.columns=['Category',	'City',	'delivery_delay',	'Orders',	'Sales',	'CustomerPurchaseHistory']

df_dl1=df_dl.copy()
df_dl1['Rank']= df_dl1.groupby('Category')['delivery_delay'].rank(method='dense',ascending=False)
df_dl1=df_dl1[df_dl1['Rank']==1]

df_dl2=df_dl.copy()
df_dl2['Rank']= df_dl2.groupby('Category')['delivery_delay'].rank(method='dense',ascending=True)
df_dl2=df_dl2[df_dl2['Rank']==1]

rat_rt_s= pd.concat((df_dl1,df_dl2)).sort_values(['Category','delivery_delay'],ascending=False)
rat_rt_s = rat_rt_s[['Category', 'City', 'delivery_delay', 'Orders', 'Sales','CustomerPurchaseHistory']]
rat_rt_s.set_index(['Category',	'City'])

# What is the average orders by city, orders, sales, returns, loss  , Tierwise , kepping minimum and maximim for orders

df_rt=df[df['return_delay']>0]

df_t=df.groupby(['Tier','City'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count',
                                                                      'Quantity':'sum','Sales':'sum'}).reset_index()
df_t.columns=[ 'Tier',	'City',	'Orders',	'Quantity',	'Sales']
df_t_rt=df_rt.groupby(['Tier','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_t_rt.columns=[ 'Tier',	'City',	'Returns', 'Loss']

t_rt= pd.merge(df_t,df_t_rt,on=['Tier','City'],how='inner')
t_rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in t_rt['Sales'] ]
t_rt['Loss']=[  f'{round(i/1000000,2)} M'  for i in t_rt['Loss'] ]
t_rt['Rank']=t_rt.groupby('Tier')['Orders'].rank(method='dense',ascending=False)
t_rt=t_rt[t_rt['Rank']==1]

t_rt2= pd.merge(df_t,df_t_rt,on=['Tier','City'],how='inner')
t_rt2['Sales']=[  f'{round(i/1000000,2)} M'  for i in t_rt2['Sales'] ]
t_rt2['Loss']=[  f'{round(i/1000000,2)} M'  for i in t_rt2['Loss'] ]
t_rt2['Rank']=t_rt2.groupby('Tier')['Orders'].rank(method='dense',ascending=False)
t_rt2=t_rt2[t_rt2['Rank']==1]

pd.concat((t_rt,t_rt2)).sort_values(['Tier','Orders'],ascending=False )[['Tier',	'City',	'Orders',	'Quantity',	'Sales',
                                                                         'Returns',	'Loss']].set_index(['Tier','City'])

# Which warranty durations correspond to the least and most orders along withs its quantity,sales, return, loss, product category wise

df_rt=df[df['return_delay']>0]

df_w= df.groupby(['Category','Product_Warranty'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count',
                                                                                 'Quantity':'sum','Sales':'sum'}).reset_index()
df_w.columns=['Category', 'Product_Warranty', 'Orders', 'Quantity', 'Sales']
df_w_t= df_rt.groupby(['Category','Product_Warranty'])[['OrderID','Sales']].agg({'OrderID':'count',
                                                                                 'Sales':'sum'}).reset_index()
df_w_t.columns=['Category', 'Product_Warranty', 'Return', 'Loss']

w_rt= pd.merge(df_w,df_w_t,on=['Category',	'Product_Warranty'],how='left')
w_rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in w_rt['Sales'] ]
w_rt['Loss']=[  f'{round(i/1000000,2)} M'  for i in w_rt['Loss'] ]
w_rt['Rank']=w_rt.groupby('Category')['Orders'].rank(method='dense',ascending=False)
w_rt=w_rt[w_rt['Rank']==1]

w_rt2= pd.merge(df_w,df_w_t,on=['Category',	'Product_Warranty'],how='left')
w_rt2['Sales']=[  f'{round(i/1000000,2)} M'  for i in w_rt2['Sales'] ]
w_rt2['Loss']=[  f'{round(i/1000000,2)} M'  for i in w_rt2['Loss'] ]
w_rt2['Rank']=w_rt2.groupby('Category')['Orders'].rank(method='dense',ascending=True)
w_rt2=w_rt2[w_rt2['Rank']==1]

pd.concat((w_rt,w_rt2)).sort_values(['Category','Orders'],ascending=False )[['Category','Product_Warranty',	'Orders',
                                                           'Quantity',	'Sales',	'Return',	'Loss']].set_index(['Category','Product_Warranty'])

# What’s the net revenue based on single category ,statewise  ?

df_rt=df[df['return_delay']>0]

df_w= df.groupby(['State','Category'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count',
                                                                                 'Quantity':'sum','Sales':'sum'}).reset_index()
df_w.columns=['State','Category',  'Orders', 'Quantity', 'Sales']
df_w_t= df_rt.groupby(['State','Category'])[['OrderID','Sales']].agg({'OrderID':'count',
                                                                                 'Sales':'sum'}).reset_index()
df_w_t.columns=['State','Category', 'Return', 'Loss']

w_rt= pd.merge(df_w,df_w_t,on=['State','Category'],how='left')
w_rt['Net_Revenue']=w_rt['Sales']-w_rt['Loss']
w_rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in w_rt['Sales'] ]
w_rt['Loss']=[  f'{round(i/1000000,2)} M'  for i in w_rt['Loss'] ]
w_rt['Rank']=w_rt.groupby('State')['Net_Revenue'].rank(method='dense',ascending=False)
w_rt=w_rt[w_rt['Rank']==1]
w_rt['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in w_rt['Net_Revenue'] ]

w_rt2= pd.merge(df_w,df_w_t,on=['State','Category'],how='left')
w_rt2['Net_Revenue']=w_rt2['Sales']-w_rt2['Loss']
w_rt2['Sales']=[  f'{round(i/1000000,2)} M'  for i in w_rt2['Sales'] ]
w_rt2['Loss']=[  f'{round(i/1000000,2)} M'  for i in w_rt2['Loss'] ]
w_rt2['Rank']=w_rt2.groupby('State')['Net_Revenue'].rank(method='dense',ascending=True)
w_rt2=w_rt2[w_rt2['Rank']==1]
w_rt2['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in w_rt2['Net_Revenue'] ]


pd.concat((w_rt,w_rt2)).sort_values(['State','Net_Revenue'],ascending=False)[['State','Category',	'Orders',	'Quantity',
                                                                  'Sales',	'Return',	'Loss','Net_Revenue']].set_index(['State','Category'])

# What are the most popular and least popular products in each warenty, based on orders, qty ,sales, return, loss

df_rt=df[df['return_delay']>0]

df_o= df.groupby(['Product_Warranty','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count',
                                                                                     'Quantity':'sum','Sales':'sum'}).reset_index()
df_o.columns=['Warenty','Product','Orders','Quantity','Sales']
df_rt_o=df_rt.groupby(['Product_Warranty','Product_Name'])[['OrderID','Sales']].agg({'OrderID':'count',
                                                                                     'Sales':'sum'}).reset_index()
df_rt_o.columns=['Warenty','Product','Return','Loss']

rt_o= pd.merge(df_o,df_rt_o,how='inner',on=['Warenty','Product'])
rt_o['Rank']=rt_o.groupby('Warenty')['Orders'].rank(method='dense',ascending=False)
rt_o=rt_o[rt_o['Rank']==1]
rt_o['Sales']=[  f'{round(i/1000000,2)} M'  for i in rt_o['Sales'] ]
rt_o['Loss']=[  f'{round(i/1000000,2)} M'  for i in rt_o['Loss'] ]

rt_o2= pd.merge(df_o,df_rt_o,how='inner',on=['Warenty','Product'])
rt_o2['Rank']=rt_o2.groupby('Warenty')['Orders'].rank(method='dense',ascending=True)
rt_o2=rt_o2[rt_o2['Rank']==1]
rt_o2['Sales']=[  f'{round(i/1000000,2)} M'  for i in rt_o2['Sales'] ]
rt_o2['Loss']=[  f'{round(i/1000000,2)} M'  for i in rt_o2['Loss'] ]

pd.concat((rt_o,rt_o2)).sort_values(['Warenty','Orders'],ascending=False )[['Warenty',	'Product',
                                                                 'Orders',	'Quantity',	'Sales',	'Return',	'Loss']].set_index(['Warenty','Product'])

# What is the average product rating by Tier based on rating,along with orders,previous purchase history, sales

df_o= df.groupby(['Tier','Product_Name'])[['ProductRating','OrderID',
                                     'CustomerPurchaseHistory','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                              'CustomerPurchaseHistory':'sum','Sales':'sum'}).reset_index()

df_o2=df_o.copy()

df_o['Rank']=df_o.groupby('Tier')['ProductRating'].rank(method='dense',ascending=False)
df_o['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_o['Sales'] ]
df_o['ProductRating']=[  round(i,2)  for i in df_o['ProductRating'] ]
df_o=df_o[df_o['Rank']==1]
df_o.columns=['Tier','Product_Name',	'Rating','Orders','Purchase_History',	'Sales','Rank']

df_o2['Rank']=df_o2.groupby('Tier')['ProductRating'].rank(method='dense',ascending=True)
df_o2['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_o2['Sales'] ]
df_o2['ProductRating']=[  round(i,2)  for i in df_o2['ProductRating'] ]
df_o2=df_o2[df_o2['Rank']==1]
df_o2.columns=['Tier','Product_Name',	'Rating','Orders','Purchase_History',	'Sales','Rank']

pd.concat((df_o,df_o2)).sort_values(['Tier','Rating'],ascending=False )[['Tier','Product_Name',	'Rating','Orders',
                                                                                'Purchase_History','Sales']].set_index(['Tier','Product_Name'])

# What are the most and least popular month in each state, based on orders , along with quantity, sales, returns and loss

df_rt=df[df['return_delay']>0]
df_o= df.groupby(['State','Month'])[['OrderID','Quantity','Sales','ProductRating']].agg({'OrderID':'count','Quantity':'sum',
                                                                            'Sales':'sum','ProductRating':'mean'}).reset_index()
df_o_rt= df_rt.groupby(['State','Month'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['State',	'Month','Orders',	'Quantity',	'Sales','Ratings']
df_o_rt.columns=['State',	'Month','Returns',	'Loss']

rt_o= pd.merge(df_o,df_o_rt,how='inner',on=['State',	'Month'])
rt_o['Sales']=[  f'{round(i/1000000,2)} M'  for i in rt_o['Sales'] ]
rt_o['Loss']=[  f'{round(i/1000000,2)} M'  for i in rt_o['Loss'] ]
rt_o['Ratings']= [ round(i,2) for i in rt_o['Ratings'] ]
rt_o2=rt_o.copy()

rt_o['Rank']=rt_o.groupby('State')['Quantity'].rank(method='dense',ascending=False)
rt_o=rt_o[rt_o['Rank']==1]

rt_o2['Rank']=rt_o2.groupby('State')['Quantity'].rank(method='dense',ascending=True)
rt_o2=rt_o2[rt_o2['Rank']==1]

pd.concat((rt_o,rt_o2)).sort_values(['State','Quantity'],ascending=False)[['State', 'Month', 'Orders', 'Quantity', 'Sales',
                                                                           'Ratings', 'Returns','Loss']].set_index(['State','Month'])

# Compare return risk between product categories , along with return history, loss, Monthwise

df_rt=df[df['return_delay']>0]

df_o= df.groupby(['Month','Month_N','Category'])['CustomerReturnHistory'].sum().reset_index()
df_o_rt= df_rt.groupby(['Month','Month_N','Category'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o_rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_o_rt['Sales'] ]

o_rt=pd.merge( df_o_rt,df_o,how='right',on=['Month',	'Month_N',	'Category'])
o_rt.columns = ['Month', 'Month_N', 'Category', 'Return', 'Loss','Return_History']
o_rt2=o_rt.copy()

o_rt['Rank']=o_rt.groupby('Month')['Return'].rank(method='dense',ascending=False)
o_rt=o_rt[o_rt['Rank']==1]

o_rt2['Rank']=o_rt2.groupby('Month')['Return'].rank(method='dense',ascending=True)
o_rt2=o_rt2[o_rt2['Rank']==1]

pd.concat((o_rt,o_rt2)).sort_values(['Month_N','Return'],ascending=False)[['Month','Category',
                                                                         'Return',	'Loss',	'Return_History']].set_index(['Month','Category'])

# What products are most affected by delivery delays, category wise and which is the least ?

df_h= df.groupby(['Category','Product_Name'])['delivery_delay'].mean().reset_index()
df_h['delivery_delay']= [ round(i,2) for i in df_h['delivery_delay']   ]
df_h2=df_h.copy()

df_h['Rank']=df_h.groupby('Category')['delivery_delay'].rank(method='dense',ascending=False)
df_h=df_h[df_h['Rank']==1]
df_h['delivery_delay']= [ f'{i} days' for i in df_h['delivery_delay']  ]

df_h2['Rank']=df_h2.groupby('Category')['delivery_delay'].rank(method='dense',ascending=True)
df_h2=df_h2[df_h2['Rank']==1]
df_h2['delivery_delay']= [ f'{i} days' for i in df_h2['delivery_delay'] ]

pd.concat((df_h,df_h2)).sort_values(['Category','delivery_delay'],ascending=False)[['Category',
                                                                                    'Product_Name','delivery_delay']].set_index(['Category','Product_Name'])

"""## D) Sales Analysis"""

# What is the total sales , total loss and net revenue per month, Tier wise

df_rt=df[df['return_delay']>0]

df_t1=df[df['Tier']=='Tier 1']
df_t2=df[df['Tier']=='Tier 2']
df_t3=df[df['Tier']=='Tier 3']

df_rt_t1=df_rt[df_rt['Tier']=='Tier 1']
df_rt_t2=df_rt[df_rt['Tier']=='Tier 2']
df_rt_t3=df_rt[df['Tier']=='Tier 3']

t1= df_t1.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t1.columns=['Month', 'Month_N', 'Sales_Tier_1']
t2= df_t2.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t2.columns=['Month', 'Month_N', 'Sales_Tier_2']
t3= df_t3.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t3.columns=['Month', 'Month_N', 'Sales_Tier_3']
sales_tier=pd.merge(pd.merge(t1,t2,how='inner',on=['Month', 'Month_N']),t3,how='inner',on=['Month', 'Month_N'])

t1_rt= df_rt_t1.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t1_rt.columns=['Month', 'Month_N', 'Loss_Tier_1']
t2_rt= df_rt_t2.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t2_rt.columns=['Month', 'Month_N', 'Loss_Tier_2']
t3_rt= df_rt_t3.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
t3_rt.columns=['Month', 'Month_N', 'Loss_Tier_3']
loss_tier=pd.merge(pd.merge(t1_rt,t2_rt,how='inner',on=['Month', 'Month_N']),t3_rt,how='inner',on=['Month', 'Month_N'])
net_rev=pd.merge(sales_tier,loss_tier,how='inner',on=['Month', 'Month_N', ])

net_rev['Net_Revenue_Tier_1']=net_rev['Sales_Tier_1']-net_rev['Loss_Tier_1']
net_rev['Net_Revenue_Tier_2']=net_rev['Sales_Tier_2']-net_rev['Loss_Tier_2']
net_rev['Net_Revenue_Tier_3']=net_rev['Sales_Tier_3']-net_rev['Loss_Tier_3']

net_rev['Sales_Tier_1']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Sales_Tier_1'] ]
net_rev['Sales_Tier_2']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Sales_Tier_2'] ]
net_rev['Sales_Tier_3']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Sales_Tier_3'] ]

net_rev['Loss_Tier_1']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Loss_Tier_1'] ]
net_rev['Loss_Tier_2']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Loss_Tier_2'] ]
net_rev['Loss_Tier_3']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Loss_Tier_3'] ]

net_rev['Net_Revenue_Tier_1']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Net_Revenue_Tier_1'] ]
net_rev['Net_Revenue_Tier_2']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Net_Revenue_Tier_2'] ]
net_rev['Net_Revenue_Tier_3']=[  f'{round(i/1000000,2)} M'  for i in net_rev['Net_Revenue_Tier_3'] ]

net_rev.sort_values('Month_N',inplace=True)
net_rev=net_rev[['Month', 'Sales_Tier_1','Loss_Tier_1','Net_Revenue_Tier_1',
                 'Sales_Tier_2', 'Loss_Tier_2','Net_Revenue_Tier_2',
                 'Sales_Tier_3', 'Loss_Tier_3', 'Net_Revenue_Tier_3']]
net_rev

# Which category contributes most to total sales and loss and which the least , quarterwise

df_rt=df[df['return_delay']>0]

sl=df.groupby(['Quarter','Quarter_N','Category'])['Sales'].sum().reset_index()
rt=df_rt.groupby(['Quarter','Quarter_N','Category'])['Sales'].sum().reset_index()

sl2=sl.copy()
sl['Rank']=sl.groupby(['Quarter'])['Sales'].rank(method='dense',ascending=False)
sl['Sales']=[  f'{round(i/1000000,2)} M'  for i in sl['Sales'] ]
sl=sl[sl['Rank']==1]
sl2['Rank']=sl2.groupby(['Quarter'])['Sales'].rank(method='dense',ascending=True)
sl2['Sales']=[  f'{round(i/1000000,2)} M'  for i in sl2['Sales'] ]
sl2=sl2[sl2['Rank']==1]
sl_f= pd.concat((sl,sl2)).sort_values(['Quarter_N','Sales'],ascending=False)[['Quarter','Category','Sales']]
sl_f.columns=['Quarter', 'Category_Order', 'Sales']

rt2=rt.copy()
rt['Rank']=rt.groupby(['Quarter'])['Sales'].rank(method='dense',ascending=False)
rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in rt['Sales'] ]
rt=rt[rt['Rank']==1]
rt2['Rank']=rt2.groupby(['Quarter'])['Sales'].rank(method='dense',ascending=True)
rt2['Sales']=[  f'{round(i/1000000,2)} M'  for i in rt2['Sales'] ]
rt2=rt2[rt2['Rank']==1]
rt_f= pd.concat((rt,rt2)).sort_values(['Quarter_N','Sales'],ascending=False)[['Quarter','Category','Sales']]
rt_f.columns=['Quarter', 'Category_Return', 'Return']

print('Quarterwise Sales: \n ',sl_f)
print('\n')
print('Quarterwise Loss: \n ',rt_f)

# What is the sales trend by quarter, along with orders ,quantity, Purchase History, Return History, statewise, both most and least

sl= df.groupby(['State','Quarter','Quarter_N'])[['OrderID','Quantity','CustomerPurchaseHistory',
                                             'CustomerReturnHistory','Sales' ]].agg({'OrderID':'count','Quantity':'sum',
                                                                                     'CustomerPurchaseHistory':'sum',
                                                                                     'CustomerReturnHistory':'sum','Sales':'sum'}).reset_index()
sl.columns=['State', 'Quarter', 'Quarter_N', 'Orders', 'Quantity','CustomerPurchaseHistory', 'CustomerReturnHistory', 'Sales']
sl2=sl.copy()

sl['Rank']=sl.groupby('State')['Sales'].rank(method='dense',ascending=False)
sl=sl[sl['Rank']==1]
sl= sl[['State', 'Quarter', 'Orders', 'Quantity', 'CustomerPurchaseHistory', 'CustomerReturnHistory', 'Sales']]
sl['Sales']=[  f'{round(i/1000000,2)} M'  for i in sl['Sales'] ]

sl2['Rank']=sl2.groupby('State')['Sales'].rank(method='dense',ascending=True)
sl2=sl2[sl2['Rank']==1]
sl2= sl2[['State', 'Quarter', 'Orders', 'Quantity', 'CustomerPurchaseHistory', 'CustomerReturnHistory', 'Sales']]
sl2['Sales']=[  f'{round(i/1000000,2)} M'  for i in sl2['Sales'] ]

pd.concat((sl,sl2)).sort_values(['State','Sales'],ascending=False).set_index(['State','Quarter'])

# Compare orders, qty, sales, return and loss growth  MoM.

df_rt=df[df['return_delay']>0]

od= df.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')
od=od[['Month','OrderID']]
od.columns=['Month','Orders']
od['Prev_Orders']=od['Orders'].shift().fillna(0)
od['MOM_Orders']= (od['Orders']-od['Prev_Orders'])/od['Prev_Orders']*100
od['MOM_Orders']=np.where(od['MOM_Orders']==np.inf,0,od['MOM_Orders'])
od['MOM_Orders']=[ round(i,2) for i in od['MOM_Orders'] ]

od2= df.groupby(['Month','Month_N'])['Sales'].sum().reset_index().sort_values('Month_N')
od2=od2[['Month','Sales']]
od2.columns=['Month','Sales']
od2['Prev_Sales']=od2['Sales'].shift().fillna(0)
od2['MOM_Sales']= (od2['Sales']-od2['Prev_Sales'])/od2['Prev_Sales']*100
od2['MOM_Sales']=np.where(od2['MOM_Sales']==np.inf,0,od2['MOM_Sales'])
od2['MOM_Sales']=[ round(i,2) for i in od2['MOM_Sales'] ]

od3= df.groupby(['Month','Month_N'])['Quantity'].sum().reset_index().sort_values('Month_N')
od3=od3[['Month','Quantity']]
od3.columns=['Month','Quantity']
od3['Prev_Quantity']=od3['Quantity'].shift().fillna(0)
od3['MOM_Quantity']= (od3['Quantity']-od3['Prev_Quantity'])/od3['Prev_Quantity']*100
od3['MOM_Quantity']=np.where(od3['MOM_Quantity']==np.inf,0,od3['MOM_Quantity'])
od3['MOM_Quantity']=[ round(i,2) for i in od3['MOM_Quantity'] ]

rt= df.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')
rt=rt[['Month','OrderID']]
rt.columns=['Month','Return']
rt['Prev_Return']=rt['Return'].shift().fillna(0)
rt['MOM_Return']= (rt['Return']-rt['Prev_Return'])/rt['Prev_Return']*100
rt['MOM_Return']=np.where(rt['MOM_Return']==np.inf,0,rt['MOM_Return'])
rt['MOM_Return']=[ round(i,2) for i in rt['MOM_Return'] ]

rt2= df.groupby(['Month','Month_N'])['Sales'].sum().reset_index().sort_values('Month_N')
rt2=rt2[['Month','Sales']]
rt2.columns=['Month','Loss']
rt2['Prev_Loss']=rt2['Loss'].shift().fillna(0)
rt2['MOM_Loss']= (rt2['Loss']-rt2['Prev_Loss'])/rt2['Prev_Loss']*100
rt2['MOM_Loss']=np.where(rt2['MOM_Loss']==np.inf,0,rt2['MOM_Loss'])
rt2['MOM_Loss']=[ round(i,2) for i in rt2['MOM_Loss'] ]

od_f= pd.merge(pd.merge(od,od3,how='inner',on='Month'),od2,how='inner',on='Month')
rt_f=pd.merge(rt,rt2,how='inner',on='Month')

mom_f= pd.merge(od_f,rt_f,how='inner',on='Month')
mom_f['Sales']=[  f'{round(i/1000000000,2)} B'  for i in mom_f['Sales'] ]
mom_f['Prev_Sales']=[  f'{round(i/1000000000,2)} B'  for i in mom_f['Prev_Sales'] ]
mom_f['Loss']=[  f'{round(i/1000000000,2)} B'  for i in mom_f['Loss'] ]
mom_f['Prev_Loss']=[  f'{round(i/1000000000,2)} B'  for i in mom_f['Prev_Loss'] ]
mom_f

# Compare orders, qty, sales, return and loss growth QoQ

df_rt=df[df['return_delay']>0]

od= df.groupby(['Quarter','Quarter_N'])['OrderID'].count().reset_index().sort_values('Quarter_N')
od=od[['Quarter','OrderID']]
od.columns=['Quarter','Orders']
od['Prev_Orders']=od['Orders'].shift().fillna(0)
od['QOQ_Orders']= (od['Orders']-od['Prev_Orders'])/od['Prev_Orders']*100
od['QOQ_Orders']=np.where(od['QOQ_Orders']==np.inf,0,od['QOQ_Orders'])
od['QOQ_Orders']=[ round(i,2) for i in od['QOQ_Orders'] ]

od2= df.groupby(['Quarter','Quarter_N'])['Sales'].sum().reset_index().sort_values('Quarter_N')
od2=od2[['Quarter','Sales']]
od2.columns=['Quarter','Sales']
od2['Prev_Sales']=od2['Sales'].shift().fillna(0)
od2['QOQ_Sales']= (od2['Sales']-od2['Prev_Sales'])/od2['Prev_Sales']*100
od2['QOQ_Sales']=np.where(od2['QOQ_Sales']==np.inf,0,od2['QOQ_Sales'])
od2['QOQ_Sales']=[ round(i,2) for i in od2['QOQ_Sales'] ]

od3= df.groupby(['Quarter','Quarter_N'])['Quantity'].sum().reset_index().sort_values('Quarter_N')
od3=od3[['Quarter','Quantity']]
od3.columns=['Quarter','Quantity']
od3['Prev_Quantity']=od3['Quantity'].shift().fillna(0)
od3['QOQ_Quantity']= (od3['Quantity']-od3['Prev_Quantity'])/od3['Prev_Quantity']*100
od3['QOQ_Quantity']=np.where(od3['QOQ_Quantity']==np.inf,0,od3['QOQ_Quantity'])
od3['QOQ_Quantity']=[ round(i,2) for i in od3['QOQ_Quantity'] ]

rt= df.groupby(['Quarter','Quarter_N'])['OrderID'].count().reset_index().sort_values('Quarter_N')
rt=rt[['Quarter','OrderID']]
rt.columns=['Quarter','Return']
rt['Prev_Return']=rt['Return'].shift().fillna(0)
rt['QOQ_Return']= (rt['Return']-rt['Prev_Return'])/rt['Prev_Return']*100
rt['QOQ_Return']=np.where(rt['QOQ_Return']==np.inf,0,rt['QOQ_Return'])
rt['QOQ_Return']=[ round(i,2) for i in rt['QOQ_Return'] ]

rt2= df.groupby(['Quarter','Quarter_N'])['Sales'].sum().reset_index().sort_values('Quarter_N')
rt2=rt2[['Quarter','Sales']]
rt2.columns=['Quarter','Loss']
rt2['Prev_Loss']=rt2['Loss'].shift().fillna(0)
rt2['QOQ_Loss']= (rt2['Loss']-rt2['Prev_Loss'])/rt2['Prev_Loss']*100
rt2['QOQ_Loss']=np.where(rt2['QOQ_Loss']==np.inf,0,rt2['QOQ_Loss'])
rt2['QOQ_Loss']=[ round(i,2) for i in rt2['QOQ_Loss'] ]

od_f= pd.merge(pd.merge(od,od3,how='inner',on='Quarter'),od2,how='inner',on='Quarter')
rt_f=pd.merge(rt,rt2,how='inner',on='Quarter')

qoq_f= pd.merge(od_f,rt_f,how='inner',on='Quarter')
qoq_f['Sales']=[  f'{round(i/1000000000,2)} B'  for i in qoq_f['Sales'] ]
qoq_f['Prev_Sales']=[  f'{round(i/1000000000,2)} B'  for i in qoq_f['Prev_Sales'] ]
qoq_f['Loss']=[  f'{round(i/1000000000,2)} B'  for i in qoq_f['Loss'] ]
qoq_f['Prev_Loss']=[  f'{round(i/1000000000,2)} B'  for i in qoq_f['Prev_Loss'] ]
qoq_f

# Identify days with highest & lowest average revenue, with total orders ,total quantity ,Purchase_History and Return_History monthwise

df_s= df.groupby(['Month','Month_N','Day'])[['Sales','OrderID','Quantity',
                                       'CustomerPurchaseHistory', 'CustomerReturnHistory']].agg({'Sales':'mean','OrderID':'count',
                                                                                                 'Quantity':'sum','CustomerPurchaseHistory':'sum',
                                                                                                 'CustomerReturnHistory':'sum'}).reset_index()
df_s['Sales']=[ round(i,2) for i in df_s['Sales']  ]
df_s2=df_s.copy()

df_s['Rank']=df_s.groupby('Month')['Sales'].rank(method='dense',ascending=False)
df_s=df_s[df_s['Rank']==1].sort_values(['Month_N','Sales'],ascending=False)
df_s=df_s[['Month','Month_N','Day', 'Sales', 'OrderID', 'Quantity','CustomerPurchaseHistory', 'CustomerReturnHistory']]
df_s.columns=['Month','Month_N', 'Day', 'Sales', 'Orders', 'Quantity','Purchase_History', 'Return_History']

df_s2['Rank']=df_s2.groupby('Month')['Sales'].rank(method='dense',ascending=True)
df_s2=df_s2[df_s2['Rank']==1].sort_values(['Month_N','Sales'],ascending=False)
df_s2=df_s2[['Month','Month_N', 'Day', 'Sales', 'OrderID', 'Quantity','CustomerPurchaseHistory', 'CustomerReturnHistory']]
df_s2.columns=['Month','Month_N', 'Day', 'Sales', 'Orders', 'Quantity','Purchase_History', 'Return_History']
pd.concat((df_s,df_s2)).sort_values('Month_N')[['Month', 'Day', 'Sales', 'Orders', 'Quantity',
                                                'Purchase_History', 'Return_History']].set_index(['Month','Day'])

# Compare express vs standard shipping revenue, orders, quantity, return & loss,  Statewise

df_ex=df[df['ShippingMode']=='Express']
df_st=df[df['ShippingMode']=='Standard']

df_rt_ex=df[df['return_delay']>0][df['ShippingMode']=='Express']
df_rt_st=df[df['return_delay']>0][df['ShippingMode']=='Standard']

ex=df_ex.groupby('State')[['Sales','OrderID','Quantity']].agg({'Sales':'sum','OrderID':'count','Quantity':'sum'}).reset_index()
ex.columns=['State', 'Sales_Express', 'Order_Express', 'Quantity_Express']
st=df_st.groupby('State')[['Sales','OrderID','Quantity']].agg({'Sales':'sum','OrderID':'count','Quantity':'sum'}).reset_index()
st.columns=['State', 'Sales_Standard', 'Order_Standard', 'Quantity_Standard']

ex_rt=df_rt_ex.groupby('State')[['OrderID','Sales',]].agg({'OrderID':'count','Sales':'sum'}).reset_index()
ex_rt.columns=['State','Return_Express','Loss_Express']
st_rt=df_rt_st.groupby('State')[['OrderID','Sales',]].agg({'OrderID':'count','Sales':'sum'}).reset_index()
st_rt.columns=['State','Return_Standard','Loss_Standard']

ex['Sales_Express']=[  f'{round(i/1000000,2)} M'  for i in ex['Sales_Express'] ]
st['Sales_Standard']=[  f'{round(i/1000000,2)} M'  for i in st['Sales_Standard'] ]

ex_rt['Loss_Express']=[  f'{round(i/1000000,2)} M'  for i in  ex_rt['Loss_Express'] ]
st_rt['Loss_Standard']=[  f'{round(i/1000000,2)} M'  for i in st_rt['Loss_Standard'] ]

es_f= pd.merge( pd.merge(ex,ex_rt,on='State',how='inner'),pd.merge(st,st_rt,on='State',how='inner'),on='State',how='inner')
es_f=es_f[['State', 'Sales_Express', 'Sales_Standard', 'Order_Express', 'Order_Standard', 'Quantity_Express','Quantity_Standard',
              'Return_Express','Return_Standard', 'Loss_Express','Loss_Standard']]

es_f

# Top 20 cities by net revenue along with orders , Quantity, sales,Purchase_History, Return_History, Return, Loss

df_rt=df[df['return_delay']>0]

df_o= df.groupby('City')[['Sales','OrderID','Quantity','CustomerPurchaseHistory',
                    'CustomerReturnHistory']].agg({'Sales':'sum','OrderID':'count','Quantity':'sum',
                                                   'CustomerPurchaseHistory':'sum','CustomerReturnHistory':'sum'}).reset_index()
df_o.columns=['City', 'Sales', 'Orders', 'Quantity', 'Purchase_History','Return_History']

df_o_rt=df_rt.groupby('City')[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o_rt.columns=['City', 'Return', 'Loss']

o_rt= pd.merge(df_o,df_o_rt,how='inner',on='City')
o_rt['Net_Revenue']=o_rt['Sales']-o_rt['Loss']
o_rt.sort_values('Net_Revenue',ascending=False,inplace=True)

o_rt['Sales']=[  f'{round(i/1000000,2)} M'  for i in  o_rt['Sales'] ]
o_rt['Loss']=[  f'{round(i/1000000,2)} M'  for i in o_rt['Loss'] ]
o_rt['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in o_rt['Net_Revenue'] ]


o_rt.head(20)

# Compare peak vs off-peak hour sales, monthwise

df_o= df.groupby(['Month','Month_N','Hr_grp'])[['Sales','OrderID','Quantity','CustomerPurchaseHistory',
                                          'CustomerReturnHistory']].agg({'Sales':'sum','OrderID':'count','Quantity':'sum',
                                                                         'CustomerPurchaseHistory':'sum',
                                                                         'CustomerReturnHistory':'sum'}).reset_index()
df_o2=df_o.copy()
df_o['Rank']=df_o.groupby('Month')['Sales'].rank(method='dense',ascending=False)
df_o=df_o[df_o['Rank']==1]

df_o2['Rank']=df_o2.groupby('Month')['Sales'].rank(method='dense',ascending=True)
df_o2=df_o2[df_o2['Rank']==1]

df_of= pd.concat((df_o,df_o2)).sort_values(['Month_N','Sales'],ascending=False)
df_of['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_of['Sales'] ]
df_of=df_of[['Month',  'Hr_grp', 'Sales', 'OrderID', 'Quantity','CustomerPurchaseHistory', 'CustomerReturnHistory']]
df_of.columns=['Month',  'Hr_grp', 'Sales', 'Orders', 'Quantity','Purchase_History', 'Return_History']
df_of.set_index(['Month',	'Hr_grp'])

# What categories dominate weekend and weekday sales and which least dominating, statewise

df_wk=df[df['Wk_Wn']=='Weekday']
df_wn=df[df['Wk_Wn']=='Weekend']

wk= df_wk.groupby(['State','Category'])[['OrderID','Quantity','Sales','CustomerPurchaseHistory']].agg({'OrderID':'count',
                                                                                                   'Quantity':'sum','Sales':'sum',
                                                                                                   'CustomerPurchaseHistory':'sum'}).reset_index()
wk2=wk.copy()
wk['Rank']=wk.groupby('State')['Sales'].rank(method='dense',ascending=False)
wk=wk[wk['Rank']==1][['State', 'Category', 'OrderID', 'Quantity', 'Sales','CustomerPurchaseHistory']]
wk2['Rank']=wk2.groupby('State')['Sales'].rank(method='dense',ascending=True)
wk2=wk2[wk2['Rank']==1][['State', 'Category', 'OrderID', 'Quantity', 'Sales','CustomerPurchaseHistory']]
wk_f= pd.concat((wk,wk2)).sort_values(['State','Sales'],ascending=False)
wk_f.columns=['State', 'Category', 'Orders', 'Quantity', 'Sales','Purchase_History']
wk_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in wk_f['Sales'] ]


wn= df_wn.groupby(['State','Category'])[['OrderID','Quantity','Sales','CustomerPurchaseHistory']].agg({'OrderID':'count',
                                                                                                   'Quantity':'sum','Sales':'sum',
                                                                                                   'CustomerPurchaseHistory':'sum'}).reset_index()
wn2=wn.copy()
wn['Rank']=wn.groupby('State')['Sales'].rank(method='dense',ascending=False)
wn=wn[wn['Rank']==1][['State', 'Category', 'OrderID', 'Quantity', 'Sales','CustomerPurchaseHistory']]
wn2['Rank']=wn2.groupby('State')['Sales'].rank(method='dense',ascending=True)
wn2=wn2[wn2['Rank']==1][['State', 'Category', 'OrderID', 'Quantity', 'Sales','CustomerPurchaseHistory']]
wn_f= pd.concat((wn,wn2)).sort_values(['State','Sales'],ascending=False)
wn_f.columns=['State', 'Category', 'Orders', 'Quantity', 'Sales','Purchase_History']
wn_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in wn_f['Sales'] ]


print('Weekday: \n',wk_f.set_index(['State','Category']))
print('\n')
print('Weekend: \n',wn_f.set_index(['State','Category']))

# Provide high-rated products with higher revenue and low-rated products with lower revenue , along with other details ,categoryuwise

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['Category','Product_Name'])[['ProductRating','OrderID','Quantity',
                                              'CustomerPurchaseHistory',
                                              'CustomerReturnHistory','Sales']].agg({'ProductRating':'mean',
                                                                                     'OrderID':'count','Quantity':'sum',
                                                                                      'CustomerPurchaseHistory':'sum',
                                                                                      'CustomerReturnHistory':'sum',
                                                                                     'Sales':'sum'}).reset_index()
df_o.columns=['Category', 'Product_Name', 'Rating', 'Orders', 'Quantity','Purchase_History', 'Return_History', 'Sales']
df_ort=df_rt.groupby(['Category','Product_Name'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_ort.columns=['Category', 'Product_Name', 'Return', 'Loss']

df_f= pd.merge(df_o,df_ort,on=['Category','Product_Name'],how='inner')
df_f2= df_f.copy()

df_f['Rank']=df_f.groupby('Category')['Rating'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('Category')['Rating'].rank(method='dense',ascending=True)

df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]

fnl= pd.concat((df_f,df_f2)).sort_values(['Category','Rating'],ascending=False)
fnl['Sales']=[  f'{round(i/1000000,2)} M'  for i in fnl['Sales'] ]
fnl['Loss']=[  f'{round(i/1000000,2)} M'  for i in fnl['Loss'] ]
fnl['Rating']= [ round(i,2) for i in fnl['Rating'] ]
fnl=fnl[['Category', 'Product_Name', 'Rating', 'Orders', 'Quantity','Purchase_History',
                 'Return_History', 'Sales', 'Return', 'Loss']]
fnl.set_index(['Category','Product_Name'])

# Provide Agewise high and low customer engagement with all other details from orders to return

df_rt=df[df['return_delay']>0]

df_o= df.groupby(['State','Age_grp'])[['OrderID','Quantity',
                                 'CustomerPurchaseHistory', 'CustomerReturnHistory' ,'Sales']].agg({'OrderID':"count",'Quantity':'sum',
                                                                                                    'CustomerPurchaseHistory':'sum' ,
                                                                                                    'CustomerReturnHistory':'sum',
                                                                                                    'Sales':'sum'}).reset_index()
df_o.columns=['State', 'Age_grp', 'Orders', 'Quantity', 'Purchase_History','Return_History', 'Sales']
df_o_rt=df_rt.groupby(['State','Age_grp'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o_rt.columns=['State', 'Age_grp', 'Return', 'Loss']

df_f= pd.merge(df_o,df_o_rt,on=['State', 'Age_grp'],how='inner')
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']
df_f2=df_f.copy()

df_f['Rank']=df_f.groupby('State')['Sales'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f.groupby('State')['Sales'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]

fnl=pd.concat((df_f,df_f2)).sort_values(['State','Sales'],ascending=False)
fnl['Sales']=[  f'{round(i/1000000,2)} M'  for i in fnl['Sales'] ]
fnl['Loss']=[  f'{round(i/1000000,2)} M'  for i in fnl['Loss'] ]
fnl['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in fnl['Net_Revenue'] ]
fnl=fnl[['State', 'Age_grp', 'Orders', 'Quantity', 'Purchase_History','Return_History', 'Sales', 'Return', 'Loss', 'Net_Revenue']]
fnl.set_index(['State', 'Age_grp'])

#  Identify top 3 cities with growing net revenue trends, monthwise

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['Month','Month_N','City'])[['Sales','OrderID','Quantity',
                                 'CustomerPurchaseHistory', 'CustomerReturnHistory' ]].agg({'Sales':'sum','OrderID':'count','Quantity':'sum',
                                                                                             'CustomerPurchaseHistory':'sum',
                                                                                            'CustomerReturnHistory':'sum'}).reset_index()
df_r=df_rt.groupby(['Month','Month_N','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Month', 'Month_N', 'City', 'Sales', 'Orders', 'Quantity','Purchase_History', 'Return_History']
df_r.columns=['Month', 'Month_N', 'City', 'Returns', 'Loss']

df_f=pd.merge(df_o,df_r,on=['Month', 'Month_N', 'City'],how='inner')
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']

df_f['Rank']=df_f.groupby('Month')['Net_Revenue'].rank(method='dense',ascending=False)
df_f=df_f[df_f['Rank']<=5].sort_values(['Month','Rank'])
df_f.sort_values(['Month_N','Net_Revenue'],ascending=False,inplace=True)
df_f=df_f[['Month',  'City', 'Sales', 'Orders', 'Quantity','Purchase_History', 'Return_History', 'Returns', 'Loss', 'Net_Revenue']]
df_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_f['Sales'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_f['Net_Revenue'] ]
df_f.set_index(['Month','City'])

# Compare state-wise contribution to annual net revenue, and select citywise highest and lowest net revenue

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['State','City'])[['OrderID','Quantity','CustomerPurchaseHistory',
                              'CustomerReturnHistory','Sales']].agg({'OrderID':'count','Quantity':'sum','CustomerPurchaseHistory':'sum',
                                                                     'CustomerReturnHistory':'sum','Sales':'sum'}).reset_index()
df_o_rt=df_rt.groupby(['State','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['State', 'City', 'Orders', 'Quantity', 'Purchase_History','Return_History', 'Sales']
df_o_rt.columns=['State', 'City', 'Return', 'Loss']

df_f= pd.merge(df_o,df_o_rt,on=['State', 'City'],how='inner')
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']
df_f2=df_f.copy()

df_f['Rank']=df_f.groupby(['State'])['Net_Revenue'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby(['State'])['Net_Revenue'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]

df_fl=pd.concat((df_f,df_f2)).sort_values(['State','Net_Revenue'],ascending=False)
df_fl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Sales'] ]
df_fl['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Loss'] ]
df_fl['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Net_Revenue'] ]

df_fl=df_fl[['State', 'City', 'Orders', 'Quantity', 'Purchase_History','Return_History',
             'Sales', 'Return', 'Loss', 'Net_Revenue']]
df_fl.set_index(['State', 'City'])

"""## E) Rating Analysis"""

# What’s the average rating per product , categorwise showing highest and lowest, along with orders and avg sales

df_f=df.groupby(['Category','Product_Name'])[['ProductRating','OrderID','Sales']].agg({'ProductRating':'mean',
                                                                                  'OrderID':'count','Sales':'mean'}).reset_index()
df_f['Sales']=[ round(i,2) for i in df_f['Sales'] ]
df_f.columns=['Category',	'Product_Name',	'Rating',	'Orders',	'Sales']
df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('Category')['Rating'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('Category')['Rating'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl= pd.concat((df_f,df_f2)).sort_values(['Category','Rating'],ascending=False)
df_fl['Rating']=[ round(i,2) for i in df_fl['Rating'] ]
df_fl=df_fl[['Category', 'Product_Name', 'Rating', 'Orders', 'Sales']]
df_fl.set_index(['Category','Product_Name'])

# What is the variance of ratings within categories in different months

df_o=df.groupby(['Month','Month_N','Category'])[['ProductRating','OrderID','CustomerPurchaseHistory',
                                            'CustomerReturnHistory','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                                   'CustomerPurchaseHistory':'sum',
                                                                                   'CustomerReturnHistory':'sum',
                                                                                   'Sales':'sum'}).reset_index()
df_o2=df_o.copy()
df_o['Rank']=df_o.groupby('Month')['ProductRating'].rank(method='dense',ascending=False)
df_o2['Rank']=df_o2.groupby('Month')['ProductRating'].rank(method='dense',ascending=True)
df_o=df_o[df_o['Rank']==1]
df_o2=df_o2[df_o2['Rank']==2]
df_f= pd.concat((df_o,df_o2)).sort_values(['Month_N','ProductRating'],ascending=[True,False])
df_f['ProductRating']= [ round(i,2) for i in df_f['ProductRating'] ]
df_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_f['Sales'] ]
df_f.columns=['Month', 'Month_N', 'Category', 'Rating', 'Orders','Purchase_History', 'Return_History', 'Sales', 'Rank']
df_f[['Month', 'Category', 'Rating', 'Orders','Purchase_History', 'Return_History','Sales']].set_index(['Month', 'Category'])

# Are certain cities harsher in their ratings, find top 5 lowest rating quarterwise along with its return

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['Quarter','Quarter_N','City'])[['ProductRating','OrderID',
                                            'Quantity','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                      'Quantity':'sum','Sales':'sum'}).reset_index()
df_o_rt=df_rt.groupby(['Quarter','Quarter_N','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Quarter', 'Quarter_N', 'City', 'Rating', 'Orders', 'Quantity', 'Sales']
df_o_rt.columns=['Quarter', 'Quarter_N', 'City', 'Return', 'Loss']
df_f= pd.merge(df_o,df_o_rt,on=['Quarter', 'Quarter_N', 'City'],how='inner')
df_f['Rank']=df_f.groupby('Quarter')['Rating'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']<=5].sort_values(['Quarter_N','Rank'],ascending=[True,True])
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']
df_f=df_f[['Quarter', 'City', 'Rating', 'Orders', 'Quantity', 'Sales','Return', 'Loss',  'Net_Revenue']]
df_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_f['Sales'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_f['Net_Revenue'] ]
df_f['Rating']= [ round(i,2) for i in df_f['Rating'] ]
df_f.set_index(['Quarter', 'City'])

#  Compare warranty duration vs rating, highets and lowest, product categorywise

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['Category','Product_Warranty' ])[['ProductRating','OrderID','Sales']].agg({'ProductRating':'mean',
                                                                                       'OrderID':'count','Sales':'sum'}).reset_index()
df_o_rt=df_rt.groupby(['Category','Product_Warranty' ])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Category', 'Warranty', 'Rating', 'Orders', 'Sales']
df_o_rt.columns=['Category', 'Warranty', 'Return', 'Loss']
df_f= pd.merge(df_o,df_o_rt,on=['Category', 'Warranty'],how='inner')
df_f2=df_f.copy()
df_f['Rank']= df_f.groupby('Category')['Rating'].rank(method='dense',ascending=False)
df_f2['Rank']= df_f2.groupby('Category')['Rating'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_o= pd.concat((df_f,df_f2)).sort_values(['Category', 'Rating'],ascending=[True,False])
df_o['Net_Revenue']=df_o['Sales']-df_o['Loss']
df_o['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_o['Sales'] ]
df_o['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_o['Loss'] ]
df_o['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_o['Net_Revenue'] ]
df_o['Rating']= [ round(i,2) for i in df_o['Rating'] ]

df_o=df_o[['Category', 'Warranty', 'Rating', 'Orders', 'Sales', 'Return', 'Loss', 'Net_Revenue']]
df_o.set_index(['Category','Warranty'])

#  Which states provide the most and least extreme ratings, Monthwise

df_f=df.groupby(['Month','Month_N','State'])[['ProductRating','OrderID',
                                          'CustomerPurchaseHistory','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                                   'CustomerPurchaseHistory':'sum','Sales':'mean'}).reset_index()
df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('Month')['ProductRating'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('Month')['ProductRating'].rank(method='dense',ascending=True)
df_f= df_f[df_f['Rank']==1]
df_f2= df_f2[df_f2['Rank']==1]
df_fl= pd.concat((df_f,df_f2)).sort_values(['Month_N','ProductRating'],ascending=[True,False])
df_fl.columns=['Month', 'Month_N', 'State', 'Rating', 'Orders', 'Purchase_History', 'Sales', 'Rank']
df_fl=df_fl[['Month', 'State', 'Rating', 'Orders', 'Purchase_History', 'Sales']]
df_fl['Sales']=[ round(i,2) for i in df_fl['Sales'] ]
df_fl['Rating']=[ round(i,2) for i in df_fl['Rating'] ]
df_fl.set_index(['Month', 'State'])

# Compare ratings before and after return date , in different state, quarterwise

df_rt=df[df['return_delay']>0]

d1=df[df['Quarter']=='Qtr 1']
d2=df[df['Quarter']=='Qtr 2']
d3=df[df['Quarter']=='Qtr 3']
d4=df[df['Quarter']=='Qtr 4']

d_rt1=df_rt[df_rt['Quarter']=='Qtr 1']
d_rt2=df_rt[df_rt['Quarter']=='Qtr 2']
d_rt3=df_rt[df_rt['Quarter']=='Qtr 3']
d_rt4=df_rt[df_rt['Quarter']=='Qtr 4']

df_o1=d1.groupby('State')['ProductRating'].mean().reset_index()
df_o2=d2.groupby('State')['ProductRating'].mean().reset_index()
df_o3=d3.groupby('State')['ProductRating'].mean().reset_index()
df_o4=d4.groupby('State')['ProductRating'].mean().reset_index()

df_rt_o1=d_rt1.groupby('State')['ProductRating'].mean().reset_index()
df_rt_o2=d_rt2.groupby('State')['ProductRating'].mean().reset_index()
df_rt_o3=d_rt3.groupby('State')['ProductRating'].mean().reset_index()
df_rt_o4=d_rt4.groupby('State')['ProductRating'].mean().reset_index()

df_f1= pd.merge(df_o1,df_rt_o1,how='inner',on='State')
df_f1.columns=['State', 'Rating_Before_Return_Qtr_1', 'Rating_After_Return_Qtr_1']
df_f1['Rating_Before_Return_Qtr_1']= [ round(i,3) for i in df_f1['Rating_Before_Return_Qtr_1'] ]
df_f1['Rating_After_Return_Qtr_1']= [ round(i,3) for i in df_f1['Rating_After_Return_Qtr_1'] ]

df_f2= pd.merge(df_o2,df_rt_o2,how='inner',on='State')
df_f2.columns=['State', 'Rating_Before_Return_Qtr_2', 'Rating_After_Return_Qtr_2']
df_f2['Rating_Before_Return_Qtr_2']= [ round(i,3) for i in df_f2['Rating_Before_Return_Qtr_2'] ]
df_f2['Rating_After_Return_Qtr_2']= [ round(i,3) for i in df_f2['Rating_After_Return_Qtr_2'] ]

df_f3= pd.merge(df_o3,df_rt_o3,how='inner',on='State')
df_f3.columns=['State', 'Rating_Before_Return_Qtr_3', 'Rating_After_Return_Qtr_3']
df_f3['Rating_Before_Return_Qtr_3']= [ round(i,3) for i in df_f3['Rating_Before_Return_Qtr_3'] ]
df_f3['Rating_After_Return_Qtr_3']= [ round(i,3) for i in df_f3['Rating_After_Return_Qtr_3'] ]

df_f4= pd.merge(df_o4,df_rt_o4,how='inner',on='State')
df_f4.columns=['State', 'Rating_Before_Return_Qtr_4', 'Rating_After_Return_Qtr_4']
df_f4['Rating_Before_Return_Qtr_4']= [ round(i,3) for i in df_f4['Rating_Before_Return_Qtr_4'] ]
df_f4['Rating_After_Return_Qtr_4']= [ round(i,3) for i in df_f4['Rating_After_Return_Qtr_4'] ]

pd.merge(pd.merge(df_f1,df_f2,on='State',how='inner'),pd.merge(df_f3,df_f4,on='State',how='inner'),on='State',how='inner')

# What’s the percentage return for orders,quantity and Loss of greater than 3-star rated products?

df_r5= df[df['ProductRating']>=3]
df_rt=df_r5[df_r5['return_delay']>0]

df_o= df_r5.groupby('Product_Name')[['ProductRating','OrderID',
                                     'Quantity','Sales']].agg({ 'ProductRating':'mean','OrderID':'count',
                                                               'Quantity':'sum','Sales':'sum'}).reset_index()
df_o_rt=df_rt.groupby('Product_Name')[['OrderID','Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum','Sales':'sum'}).reset_index()

df_o.columns=['Product_Name','Rating','Orders', 'Quantity', 'Sales']
df_o_rt.columns=['Product_Name', 'Return', 'Qty_Return', 'Loss']

df_f= pd.merge(df_o,df_o_rt,on='Product_Name',how='inner')
df_f['% Return']= [ f'{round(i,2)} %' for i in  (df_f['Return']/df_f['Orders']*100) ]
df_f['% Qty_Return']= [ f'{round(i,2)} %' for i in  (df_f['Qty_Return']/df_f['Quantity']*100) ]
df_f['% Loss']= [ f'{round(i,2)} %' for i in  (df_f['Loss']/df_f['Sales']*100) ]
df_f['Rating']=[ round(i,2) for i in df_f['Rating'] ]
df_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_f['Sales'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]

df_f=df_f[['Product_Name','Rating','Orders', 'Return','% Return','Quantity','Qty_Return','% Qty_Return','Sales','Loss','% Loss']]
df_f.set_index('Product_Name')

# Compare rating patterns by state, rating highest and lowest product rating along with orders,quantity,sales,delivery delay,purchase history

df_f= df.groupby(['State','Product_Name'])[['ProductRating','OrderID','Quantity',
                                      'DiscountApplied','CustomerPurchaseHistory','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                                                'Quantity':'sum', 'DiscountApplied':'mean',
                                                                                                 'CustomerPurchaseHistory':'sum',
                                                                                                'Sales':'sum'}).reset_index()
df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('State')['ProductRating'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('State')['ProductRating'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl= pd.concat((df_f,df_f2)).sort_values(['State','ProductRating'],ascending=[True,False])
df_fl.columns=['State', 'Product_Name', 'Rating', 'Orders', 'Quantity','Discount', 'Purchase_History', 'Sales', 'Rank']
df_fl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Sales'] ]
df_fl['Rating']=[ round(i,2) for i in df_fl['Rating'] ]
df_fl['Discount']=[ f'{round(i,2)} %' for i in df_fl['Discount'] ]
df_fl=df_fl[['State', 'Product_Name', 'Rating', 'Orders', 'Quantity', 'Discount','Purchase_History', 'Sales']]
df_fl.set_index(['State', 'Product_Name'])

#  What’s the correlation between rating and age?

df_f= df.groupby(['Age_grp','Category'])[['ProductRating','OrderID','Quantity',
                                      'DiscountApplied','CustomerPurchaseHistory','Sales']].agg({'ProductRating':'mean','OrderID':'count',
                                                                                                'Quantity':'sum', 'DiscountApplied':'mean',
                                                                                                 'CustomerPurchaseHistory':'sum',
                                                                                                'Sales':'sum'}).reset_index()
df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('Age_grp')['ProductRating'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('Age_grp')['ProductRating'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl= pd.concat((df_f,df_f2)).sort_values(['Age_grp','ProductRating'],ascending=[True,False])
df_fl.columns=['Age_grp', 'Category', 'Rating', 'Orders', 'Quantity','Discount', 'Purchase_History', 'Sales', 'Rank']
df_fl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Sales'] ]
df_fl['Rating']=[ round(i,2) for i in df_fl['Rating'] ]
df_fl['Discount']=[ f'{round(i,2)} %' for i in df_fl['Discount'] ]
df_fl=df_fl[['Age_grp', 'Category', 'Rating', 'Orders', 'Quantity', 'Discount','Purchase_History', 'Sales']]
df_fl.set_index(['Age_grp', 'Category'])

"""## F) Return Analysis"""

# What is the overall return rate for product, statewise and identify top 3 with high return rate

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['State','Product_Name'])[['OrderID','Quantity','CustomerReturnHistory',
                                                       'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                       'CustomerReturnHistory':'sum','Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['State','Product_Name'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['State', 'Product_Name', 'Orders', 'Quantity', 'Return_History','Sales']
df_r.columns=['State', 'Product_Name', 'Return', 'Loss']

df_f= pd.merge(df_o,df_r,on=['State','Product_Name'],how='inner')
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100
df_f['Rank']=df_f.groupby('State')['% Return'].rank(method='dense',ascending=False)
df_f=df_f[df_f['Rank']<=3].sort_values(by=['State','Rank'],ascending=[True,True])
df_f['% Return']=[ f'{round(i,2)} %' for i in df_f['% Return'] ]
df_f['% Loss']=[ f'{round(i,2)} %' for i in df_f['% Loss'] ]
df_f['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_f['Sales'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f=df_f[['State', 'Product_Name', 'Orders', 'Quantity', 'Return_History','Sales', 'Return', 'Loss', '% Return', '% Loss']]
df_f.set_index(['State', 'Product_Name'])

# Which top and  age is most cited for product returns , categorywise   based on % return

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['Category','Age_grp'])[['OrderID','Quantity',
                                         'CustomerReturnHistory' ,'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                                 'CustomerReturnHistory':'sum' ,'Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['Category','Age_grp'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Category','Age_grp', 'Orders', 'Quantity','Return_History', 'Sales']
df_r.columns=['Category','Age_grp', 'Return', 'Loss']

df_f= pd.merge(df_o,df_r,on=['Category','Age_grp'],how='inner')
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100
df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('Category')['% Return'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f.groupby('Category')['% Return'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl=pd.concat((df_f,df_f2)).sort_values(by=['Category','% Return'],ascending=[True,False])
df_fl['% Return']=[ f'{round(i,2)} %' for i in df_fl['% Return'] ]
df_fl['% Loss']=[ f'{round(i,2)} %' for i in df_fl['% Loss'] ]
df_fl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Sales'] ]
df_fl['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Loss'] ]
df_fl=df_fl[['Category', 'Age_grp', 'Orders', 'Quantity', 'Return_History', 'Sales','Return', 'Loss', '% Return', '% Loss']]
df_fl.set_index(['Category', 'Age_grp'])

#  Analyze return rate by  by city and state.

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['State','City'])[['OrderID','CustomerReturnHistory',
                                   'Quantity','Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                             'CustomerReturnHistory':'sum','Sales':'sum'}).reset_index()
df_o.columns=['State', 'City', 'Orders', 'Quantity','Return_History' ,'Sales']
df_r=df_rt.groupby(['State','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_r.columns=['State', 'City', 'Return', 'Loss']

df_f=pd.merge(df_o,df_r,on=['State','City'],how='inner')
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100

df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('State')['% Return'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('State')['% Return'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl=pd.concat((df_f,df_f2)).sort_values(['State','% Return'],ascending=[True,False])

df_fl=df_fl[['State', 'City',  'Return','Return_History' ,'Loss','Net_Revenue', '% Return', '% Loss']]
df_fl['% Return']=[ f'{round(i,2)} %' for i in df_fl['% Return'] ]
df_fl['% Loss']=[ f'{round(i,2)} %' for i in df_fl['% Loss'] ]
df_fl['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Loss'] ]
df_fl['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Net_Revenue'] ]
df_fl.set_index(['State','City'])

# Which product has  return volume and Identify top and bottom categorywise

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['Category','Product_Name'])[['OrderID','Quantity',
                                         'CustomerReturnHistory' ,'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                                 'CustomerReturnHistory':'sum' ,'Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['Category','Product_Name'])[['OrderID','Quantity','Sales']].agg({'OrderID':'count',
                                                                                'Quantity':'sum','Sales':'sum'}).reset_index()
df_o.columns=['Category','Product_Name', 'Orders', 'Quantity','Return_History', 'Sales']
df_r.columns=['Category','Product_Name', 'Return','Qty_Return' ,'Loss']

df_f= pd.merge(df_o,df_r,on=['Category','Product_Name'],how='inner')
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Qty_Return']=df_f['Qty_Return']/df_f['Quantity']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100

df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('Category')['% Qty_Return'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f.groupby('Category')['% Qty_Return'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]
df_fl=pd.concat((df_f,df_f2)).sort_values(by=['Category','% Qty_Return'],ascending=[True,False])
df_fl['% Return']=[ f'{round(i,2)} %' for i in df_fl['% Return'] ]
df_fl['% Qty_Return']=[ f'{round(i,2)} %' for i in df_fl['% Qty_Return'] ]
df_fl['% Loss']=[ f'{round(i,2)} %' for i in df_fl['% Loss'] ]
df_fl['Sales']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Sales'] ]
df_fl['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Loss'] ]
df_fl=df_fl[['Category', 'Product_Name','Return','Qty_Return','Return_History','Loss' ,'% Return','% Qty_Return' ,'% Loss']]
df_fl.set_index(['Category', 'Product_Name'])

# Return risk by customer age segment, and identify top 3 city having high return

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['Age_grp','City'])[['OrderID','Quantity',
                                         'CustomerReturnHistory' ,'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                                 'CustomerReturnHistory':'sum' ,'Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['Age_grp','City'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Age_grp','City', 'Orders', 'Quantity','Return_History', 'Sales']
df_r.columns=['Age_grp','City', 'Return','Loss']
df_f= pd.merge(df_o,df_r,on=['Age_grp','City'],how='inner')
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100
df_f['Rank']=df_f.groupby('Age_grp')['Return'].rank(method='dense',ascending=False)
df_f=df_f[df_f['Rank']<=3].sort_values(['Age_grp','Rank'],ascending=[True,True])
df_f['% Return']=[ f'{round(i,2)} %' for i in df_f['% Return'] ]
df_f['% Loss']=[ f'{round(i,2)} %' for i in df_f['% Loss'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f=df_f[['Age_grp', 'City', 'Return','Return_History', 'Loss', '% Return', '% Loss']]
df_f.set_index(['Age_grp', 'City'])

# Compare weekdays vs weekends in return behavior , Monthwise

df_rt=df[df['return_delay']>0]

df_o=df.groupby(['Month','Month_N','Wk_Wn'])[['OrderID','Quantity',
                                         'CustomerReturnHistory' ,'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                                 'CustomerReturnHistory':'sum' ,'Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['Month','Month_N','Wk_Wn'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Month','Month_N','Wk_Wn', 'Orders', 'Quantity','Return_History', 'Sales']
df_r.columns=['Month','Month_N','Wk_Wn', 'Return','Loss']
df_f= pd.merge(df_o,df_r,on=['Month','Month_N','Wk_Wn'],how='inner').sort_values('Month_N')
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100
df_f['% Return']=[ f'{round(i,2)} %' for i in df_f['% Return'] ]
df_f['% Loss']=[ f'{round(i,2)} %' for i in df_f['% Loss'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f=df_f[['Month','Wk_Wn', 'Return','Return_History', 'Loss', '% Return', '% Loss']]
df_f.set_index(['Month','Wk_Wn', ])

# Which cities have the fastest return processing and which is lowest, along with total return, return history and quantity return

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['State','City'])[['return_delay','CustomerReturnHistory']].agg({'return_delay':'mean',
                                                                                            'CustomerReturnHistory':'sum' }).reset_index()
df_r=df_rt.groupby(['State','City'])[['OrderID','Quantity']].agg({'OrderID':'count','Quantity':'sum'}).reset_index()
df_o.columns=['State','City' , 'Return_Delay','Return_History']
df_r.columns=['State','City', 'Return','Qty_Return']
df_f= pd.merge(df_o,df_r,on=['State','City'],how='inner')

df_f2=df_f.copy()
df_f['Rank']=df_f.groupby('State')['Return_Delay'].rank(method='dense',ascending=False)
df_f2['Rank']=df_f2.groupby('State')['Return_Delay'].rank(method='dense',ascending=True)
df_f=df_f[df_f['Rank']==1]
df_f2=df_f2[df_f2['Rank']==1]

df_fl=pd.concat((df_f,df_f2)).sort_values(['State','Return_Delay'],ascending=[True,True])
df_fl['Return_Delay']=[ f'{round(i,2)} days' for i in df_fl['Return_Delay'] ]
df_fl=df_fl[['State','City','Return_Delay', 'Return_History', 'Return', 'Qty_Return']]
df_fl.set_index(['State','City'])

# Calculate total revenue loss due to returns per category, identifying top 3 company

df_rt=df[df['return_delay']>0]
df_o=df.groupby(['Category','Company'])[['OrderID','Quantity',
                                         'CustomerReturnHistory' ,'Sales']].agg({'OrderID':'count','Quantity':'sum',
                                                                                 'CustomerReturnHistory':'sum' ,'Sales':'sum'}).reset_index()
df_r=df_rt.groupby(['Category','Company'])[['OrderID','Sales']].agg({'OrderID':'count','Sales':'sum'}).reset_index()
df_o.columns=['Category','Company', 'Orders', 'Quantity','Return_History', 'Sales']
df_r.columns=['Category','Company', 'Return','Loss']
df_f= pd.merge(df_o,df_r,on=['Category','Company'],how='inner')
df_f['Net_Revenue']=df_f['Sales']-df_f['Loss']
df_f['% Return']=df_f['Return']/df_f['Orders']*100
df_f['% Loss']=df_f['Loss']/df_f['Sales']*100
df_f['Rank']=df_f.groupby('Category')['Loss'].rank(method='dense',ascending=False)
df_f=df_f[df_f['Rank']<=3].sort_values(['Category','Rank'],ascending=[True,True])
df_f['% Return']=[ f'{round(i,2)} %' for i in df_f['% Return'] ]
df_f['% Loss']=[ f'{round(i,2)} %' for i in df_f['% Loss'] ]
df_f['Loss']=[  f'{round(i/1000000,2)} M'  for i in df_f['Loss'] ]
df_f['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_f['Net_Revenue'] ]
df_f=df_f[['Category','Company', 'Return','Return_History', 'Loss', '% Return', '% Loss']]
df_f.set_index(['Category','Company'])

# Calculate MOM % for Return, Loss and Net Revenue

df_rt=df[df['return_delay']>0]

df_o= df.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
df_o.columns=['Month', 'Orders']
df_s= df.groupby(['Month','Month_N'])['Sales'].sum().reset_index().sort_values('Month_N')[['Month','Sales']]
df_s.columns=['Month', 'Sales']
df_r= df_rt.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
df_r.columns=['Month', 'Return']
df_l= df_rt.groupby(['Month','Month_N'])['Sales'].sum().reset_index().sort_values('Month_N')[['Month','Sales']]
df_l.columns=['Month', 'Loss']
df_nr=pd.merge(df_s,df_l,on='Month',how='inner')
df_nr['Net_Revenue']=df_nr['Sales']-df_nr['Loss']
df_nr=df_nr[['Month',  'Net_Revenue']]

df_r['Pre_Return']=df_r['Return'].shift().fillna(0)
df_l['Pre_Loss']=df_l['Loss'].shift().fillna(0)
df_nr['Pre_Net_Revenue']=df_nr['Net_Revenue'].shift().fillna(0)

df_r['MOM Return']=(df_r['Return']-df_r['Pre_Return'])/df_r['Pre_Return']*100
df_r['MOM Return']=np.where(df_r['MOM Return']==np.inf,0,df_r['MOM Return'])

df_l['MOM Loss']=(df_l['Loss']-df_l['Pre_Loss'])/df_l['Pre_Loss']*100
df_l['MOM Loss']=np.where(df_l['MOM Loss']==np.inf,0,df_l['MOM Loss'])

df_nr['MOM Net_Revenue']=(df_nr['Net_Revenue']-df_nr['Pre_Net_Revenue'])/df_nr['Pre_Net_Revenue']*100
df_nr['MOM Net_Revenue']=np.where(df_nr['MOM Net_Revenue']==np.inf,0,df_nr['MOM Net_Revenue'])

df_fl=pd.merge(pd.merge(pd.merge(df_o,df_s,on='Month',how='inner'),
                        pd.merge(df_r,df_l,on='Month',how='inner'),how='inner',on='Month'),
               df_nr,on='Month',how='inner')
df_fl=df_fl[['Month', 'Orders', 'Sales', 'Return', 'MOM Return','Loss','MOM Loss','Net_Revenue','MOM Net_Revenue']]

df_fl['MOM Return']=[ f'{round(i,2)} %' for i in df_fl['MOM Return'] ]
df_fl['MOM Loss']=[ f'{round(i,2)} %' for i in df_fl['MOM Loss'] ]
df_fl['MOM Net_Revenue']=[ f'{round(i,2)} %' for i in df_fl['MOM Net_Revenue'] ]

df_fl['Sales']=[  f'{round(i/1000000000,2)} B'  for i in df_fl['Sales'] ]
df_fl['Loss']=[  f'{round(i/1000000000,2)} B'  for i in df_fl['Loss'] ]
df_fl['Net_Revenue']=[  f'{round(i/1000000,2)} M'  for i in df_fl['Net_Revenue'] ]

df_fl

"""## GRAPHICAL ANALYSIS

## A) Sales Analysis
"""

# Plot a line graph to show daily sales trends using OrderDate.

df2=df.copy()
df2['Sales_Before_Discount']=df2['Quantity']*df2['ProductPrice']

plt.figure(figsize=(20,15))
sb.lineplot(data=df2,x='OrderDate',y='Sales',estimator='sum',label='Salse_After_Discount')
sb.lineplot(data=df2,x='OrderDate',y='Sales_Before_Discount',estimator='sum',label='Salse_Before_Discount')
plt.title('Sales Before & After Discount',color='Maroon',size=25)
plt.legend()
plt.show()

# Create a bar chart of total sales by state, product categorywise

plt.figure(figsize=(20,15))

pd.crosstab(columns=df['Category'],index=df['State'],values=df['Sales'],aggfunc='sum').plot(kind='bar',stacked=True,figsize=(20,15),colormap='tab10')
plt.title('Category vs State Sales', color='Indigo',size=25)
plt.ylabel('Sales')
plt.show()

# Visualize Quarterly sales in each category

plt.figure(figsize=(20,15))

pd.crosstab(index=df['Category'],columns=df['Quarter'],values=df['OrderID'],aggfunc='count').plot(kind='bar',stacked=True,figsize=(20,15),colormap='tab10')
plt.title('Category vs State Sales', color='Indigo',size=25)
plt.ylabel('Sales')
plt.show()

# Calculate MOM Orders

df_s= df.groupby(['Month','Month_N'])['OrderID'].count().reset_index().sort_values('Month_N')[['Month','OrderID']]
df_s.columns=['Month', 'Orders']
df_s['Pre_Orders']=df_s['Orders'].shift().fillna(0)
df_s['MOM% Orders']= (df_s['Orders']-df_s['Pre_Orders'])/df_s['Pre_Orders']*100
df_s['MOM% Orders']=np.where(df_s['MOM% Orders']==np.inf,0,df_s['MOM% Orders'])
df_sf=df_s[['Month', 'MOM% Orders']].set_index('Month')

df_sf.plot(kind='area',stacked=False,figsize=(20,15),alpha=0.5,color='red')
plt.title('MOM%  Orders', color='Maroon',size=25)
plt.ylabel('MOM% Orders')
plt.show()

# Calculate MOM Sales

df_s= df.groupby(['Month','Month_N'])['Sales'].sum().reset_index().sort_values('Month_N')[['Month','Sales']]
df_s.columns=['Month', 'Sales']
df_s['Pre_Sales']=df_s['Sales'].shift().fillna(0)
df_s['MOM% Sales']= (df_s['Sales']-df_s['Pre_Sales'])/df_s['Pre_Sales']*100
df_s['MOM% Sales']=np.where(df_s['MOM% Sales']==np.inf,0,df_s['MOM% Sales'])
df_sf=df_s[['Month', 'MOM% Sales']].set_index('Month')

df_sf.plot(kind='area',stacked=False,figsize=(20,15),alpha=0.7)
plt.title('MOM%  Sales', color='Purple',size=25)
plt.ylabel('MOM% Sales')
plt.show()

# Create a boxplot comparing sales distribution across different Payment Methods, Tierwise

plt.figure(figsize=(20,15))
sb.boxplot(data=df,x='PaymentMethod',y='Sales',hue='Tier',palette='plasma')
plt.title('Tierwise Payment Distribution', color='Purple',size=25)
plt.legend(loc=1)
plt.show()

# Plot a stacked bar chart showing total transaction by State and PaymentMethod.

df_sp=pd.crosstab(index=df['State'],columns=df['PaymentMethod'],values=df['Sales'],aggfunc='sum')
df_sp.plot(kind='barh',stacked=True,figsize=(20,30))
plt.title('Statewise Payment Transaction', color='Indigo',size=25)
plt.xlabel('Transaction')
plt.show()

# Use a violin plot to compare ProductPrice distributions across different ShippingModes on different Transaction

plt.figure(figsize=(20,8))
sb.violinplot(data=df,x='PaymentMethod',hue='ShippingMode',y='ProductPrice',split=True,palette='magma')
plt.title('Transaction vs ShippingMode Product Price', color='Indigo',size=25)
plt.show()

# Visualize average discount applied by month using a bar plot, based on Return Risk

plt.figure(figsize=(20,15*2))
sb.barplot(data=df, y='Month',x='DiscountApplied',estimator='mean',errorbar=('ci',0),hue='CustomerGender',palette='plasma')
plt.title('Genderwise Month vs Discount', color='Purple',size=25)
plt.show()

# Create a line plot to examine the price daywise based on different Tier

plt.figure(figsize=(20,15))
sb.lineplot(data=df,x='OrderDate',y='Quantity',estimator='sum',hue='Tier',palette='plasma' )
plt.title('Tierwise Daily Quantity Sold  ', color='Indigo',size=25)
plt.show()

#  Create a bar plot comparing average revenue during different hours of the day , in different state .

df_o=pd.crosstab(columns=df['Hr_grp'],index=df['State'],values=df['Sales'],aggfunc='mean')
df_o.plot(kind='barh',stacked=True,figsize=(20,15),colormap='coolwarm')
plt.title('Statewise Hourly Sales  ', color='Purple',size=25)
plt.ylabel('State')
plt.xlabel('Sales')
plt.show()

# Use a KDE plot to visualize the probability distribution of order values (Sales).

plt.figure(figsize=(20,15))
plt.hist(df['Sales'],edgecolor='black',color='purple',bins=np.arange(0,350000,25000))
plt.title('Sales Distribution',size=25,color='indigo')
plt.show()

"""## B) Customer Analysis"""

# Plot a pie chart showing the gender-wise distribution of customers, in each state

state=df['State'].unique().tolist()
plt.figure(figsize=(20,100))

for i in range(len(state)):
  df_s=df[df['State']==state[i]]
  df_d=df_s['CustomerGender'].value_counts().reset_index()
  df_d.columns=['Gender','Values']
  plt.subplot(20,2,i+1)
  plt.pie(df_d['Values'],labels=df_d['Gender'],autopct='%0.2f%%',colors=['gold','silver','red'] )
  plt.title(f'{state[i]}')


plt.show()

# Create a barplot to show  customer age by city.

city=df['City'].unique().tolist()
plt.figure(figsize=(20,100))

for i in range(len(state)):
  df_s=df[df['City']==city[i]]
  plt.subplot(20,2,i+1)
  plt.hist(df_s['CustomerAge'],bins=np.arange(18,70,5),edgecolor='black',color='gold')
  plt.title(f'{city[i]}')

plt.show()

# Create a bar chart to show average customer spending by State in different age category.

plt.figure(figsize=(20,10))
df_f=pd.crosstab(index=df['State'],columns=df['Age_grp'],values=df['Sales'],aggfunc='mean')
df_f.plot(kind='barh',stacked=True,figsize=(20,20),colormap='plasma' )
plt.title('State vs Age Avg. Spending',size=25,color='purple')
plt.xlabel('Avg. Spending')
plt.show()

# Use a volinplot to visualize CustomerAge vs Purchase History by Gender.

plt.figure(figsize=(20,10))
sb.barplot(data=df,y='Age_grp',x='CustomerPurchaseHistory',hue='CustomerGender',estimator='sum',palette='magma',errorbar=('ci',0) )
plt.title('Gender vs Age Purchase_History',size=25,color='maroon')
plt.show()

# Create a bar for total customer across different Age groups and Cities.

df_x=pd.crosstab(index=df['City'],columns=df['Age_grp'])
df_x.plot(kind='barh',stacked=True,figsize=(20,100),colormap='coolwarm' )
plt.legend(loc=1)
plt.xticks(np.arange(0,16,1))
plt.title('City vs Age Customers',size=25,color='maroon')
plt.show()

# Create a bar chart to compare customer engagement by CustomerGender, using different Transaction

df_x=pd.crosstab(index=df['PaymentMethod'],columns=df['CustomerGender'])
df_x.plot(kind='barh',stacked=True,figsize=(20,10),colormap='magma' )
plt.title('Genderwise Transaction use',size=25,color='maroon')
plt.show()

# Use a boxplot to analyze CustomerPurchaseHistory across different PaymentMethods , Tier based

plt.figure(figsize=(15,20))
sb.boxplot(data=df,y='PaymentMethod',x='CustomerPurchaseHistory' ,hue='Tier',palette='plasma' )
plt.title('Tierwise Payment method for Purchase History',size=25,color='indigo')
plt.legend(loc=1)
plt.show()

# Plot a violin plot showing return frequency (CustomerReturnHistory)  by Return Risk, in different Quarter

plt.figure(figsize=(15,8))
sb.violinplot(data=df,y='CustomerReturnHistory',x='Quarter',hue='Return_Risk',split=True,palette='magma' )
plt.title('Quarterwise Return_History based on Return_Risk ',size=25,color='purple')
plt.show()

# Create a bar plot to show CustomerPurchaseHistory by State, Quarterwise.

df_f=pd.crosstab(index=df['State'],columns=df['Quarter'],values=df['CustomerPurchaseHistory'],aggfunc='sum')
df_f.plot(kind='barh',stacked=True,colormap='plasma',figsize=(20,15))
plt.xlabel('Purchase_History')
plt.title('Statewise Purchase_History on different Quarter ',size=25,color='purple')
plt.show()

# Generate a boxlot to observe relation between Age Group and ReturnHistory in different Quarters

plt.figure(figsize=(25,15))
sb.boxplot(data=df,x='Age_grp',y='CustomerPurchaseHistory',hue='Quarter',palette='magma')
plt.title('Quarterly Age Based Purchase History ',size=25,color='indigo')
plt.legend(loc=1)
plt.yticks(np.arange(0,110,10))
plt.show()

# Create a bar chart to display state with highest Average purchase, dividing return risk

plt.figure(figsize=(15,20))
sb.barplot(data=df,y='State',x='Sales',estimator='mean',hue='Return_Risk',palette='plasma',errorbar=('ci',0) )
plt.title('Statewise Avg. Sales , with potential Return Risk',size=25,color='maroon')
plt.legend(loc=1)
plt.show()

# Plot daily comparing Purchase_History and Return_History'

plt.figure(figsize=(20,20))
sb.lineplot(data=df,x='OrderDate',y='CustomerPurchaseHistory',estimator='sum',label='Purchase_History',palette='magma')
sb.lineplot(data=df,x='OrderDate',y='CustomerReturnHistory',estimator='sum',label='Return_History',palette='plasma')
plt.title('Purchase_History vs Return_History ',size=25,color='indigo')
plt.legend(loc=1)
plt.show()

"""## C) Product & Sales Analysis"""

# Plot a bar of total sales by Category ,Tierwise

df_x=pd.crosstab(index=df['Category'],columns=df['Tier'],values=df['Sales'],aggfunc='mean')
df_x.plot(kind='bar',stacked=True, figsize=(20,15),colormap='magma')
plt.title('Tierwise Avg. Sales per Category ',size=25,color='maroon')
plt.show()

# Create a bar chart for top 10 most sold products by  orders and quantity

df_x=df.groupby(['Product_Name'])[['OrderID','Quantity']].agg({'OrderID':'count','Quantity':'sum'})
df_x.columns=['Orders','Quantity']
df_x.sort_values(['Orders','Quantity'],ascending=[False,False])
df_x.plot(kind='barh',colormap='coolwarm',figsize=(10,50) )
plt.title('Productwise Order vs Quantity ',size=25,color='indigo')
plt.show()

# Plot a line graph showing quantity sold for month in different category .

df_x=df.copy()
df_dt= pd.crosstab(index=df_x['Category'],columns=df_x['CustomerGender'],values=df_x['Quantity'],aggfunc='sum')
df_dt.plot(kind='bar',figsize=(15,10),colormap='plasma',stacked=True )
plt.title('Genderwise Order vs Quantity ',size=25,color='indigo')
plt.legend(loc=1)
plt.show()

# Use a boxplot to compare ratings across different company

plt.figure(figsize=(15,30))
sb.boxplot(data=df,y='Company',x='ProductRating',palette='magma')
plt.title('Company Rating',size=25,color='purple')
plt.xticks(np.arange(1,5.5,0.5))
plt.show()

# Generate a bar chart comparing quantity sold ProductWarranty status by Category.

df_x=pd.crosstab(index=df['Category'],columns=df['Product_Warranty'],values=df['Quantity'],aggfunc='sum')
df_x.plot(kind='bar',stacked=True,colormap='plasma',figsize=(20,20))
plt.title('Category vs Product Warenty Quantity sold',size=25,color='maroon')
plt.yticks(np.arange(0,150000,10000))
plt.show()

# Use a pieplot to show product distribution across company in different Age_grp' .

Company= df['Company'].unique().tolist()
plt.figure(figsize=(15,100))

for i in range(len(Company)):
  df_x=df[df['Company']==Company[i]]
  df_ct=df_x['Age_grp'].value_counts().reset_index()
  plt.subplot(25,2,i+1)
  plt.pie(df_ct['count'],labels=df_ct['Age_grp'],autopct='%0.2f%%',colors=['silver','blue','gold','red','orange'])
  plt.title(f"{Company[i]}")

plt.show()

# Draw a violin plot to display quantity distribution by Category ,in different ship modes.

plt.figure(figsize=(20,15))
sb.violinplot(data=df,x='Category',y='Quantity',hue='ShippingMode',split=True,palette='plasma')
plt.title('Category vs Ship Mode Quantity sold',size=25,color='purple')
plt.show()

# Plot a histogram of Sales grouped by Quarter

plt.figure(figsize=(15,10))
sb.kdeplot(data=df,x='Sales',hue='Product_Warranty',palette='magma')
plt.title(' Quarterly Sales Distribution',size=25,color='indigo')
plt.show()

# Draw a stacked bar chart of Category-wise CustomerPurchaseHistory and CustomerReturnHistory

plt.figure(figsize=(15,10))
sb.barplot(data=df,x='Category',y='CustomerPurchaseHistory',estimator='sum',errorbar=('ci',0),palette='coolwarm' )
sb.barplot(data=df,x='Category',y='CustomerReturnHistory',estimator='sum',errorbar=('ci',0),palette='plasma')
plt.ylabel('CustomerPurchaseHistory vs CustomerReturnHistory')
plt.title('Categorywise Purchase_History vs Return_History ',size=25,color='purple')
plt.show()

"""## D) Return Analysis

"""

df_rt=df[df['return_delay']>0]

# Create a pie chart of ReturnReason distribution in different Category .

reason= df['Category'].unique().tolist()
plt.figure(figsize=(15,100))

for i in range(len(reason)):
  df_x=df[df['Category']==reason[i]]
  df_ct=df_x['ReturnReason'].value_counts().reset_index()
  plt.subplot(25,2,i+1)
  plt.pie(df_ct['count'],labels=df_ct['ReturnReason'],autopct='%0.2f%%',colors=['silver','blue','gold','red','orange'])
  plt.title(f"{reason[i]}")

plt.show()

# Plot a line chart showing quantity return count using ReturnDate, in different tier

plt.figure(figsize=(15,10))
sb.lineplot(data=df_rt,x='ReturnDate',y='Sales',estimator='sum',hue='Tier',palette='magma')
plt.ylabel('Loss')
plt.title('Tierwise Overall Loss ',size=25,color='maroon')
plt.show()

# MOM Total Return

df_x= df_rt.groupby(['Month','Month_N'])['OrderID'].count().reset_index()
df_x.sort_values(by='Month_N',ascending=True,inplace=True)
df_x=df_x[['Month','OrderID']]
df_x.columns=['Month','Return']
df_x['Pre_Return']= df_x['Return'].shift()
df_x['Pre_Return']=df_x['Pre_Return'].fillna(0)
df_x['MOM% Return']=  (df_x['Return']-df_x['Pre_Return'])/df_x['Pre_Return']*100
df_x['MOM% Return']= np.where(df_x['MOM% Return']==np.inf,0,df_x['MOM% Return'])
df_x=df_x[['Month','MOM% Return']]
df_x=df_x.set_index('Month')

df_x.plot(kind='area',stacked=False,color='orange',figsize=(20,15))
plt.ylabel('MOM %')
plt.title('MOM % Return ',size=25,color='indigo')
plt.show()

# MOM Loss

df_x= df_rt.groupby(['Month','Month_N'])['Sales'].sum().reset_index()
df_x.sort_values(by='Month_N',ascending=True,inplace=True)
df_x=df_x[['Month','Sales']]
df_x.columns=['Month','Loss']
df_x['Pre_Loss']= df_x['Loss'].shift()
df_x['Pre_Loss']=df_x['Pre_Loss'].fillna(0)
df_x['MOM% Loss']=  (df_x['Loss']-df_x['Pre_Loss'])/df_x['Pre_Loss']*100
df_x['MOM% Loss']= np.where(df_x['MOM% Loss']==np.inf,0,df_x['MOM% Loss'])
df_x=df_x[['Month','MOM% Loss']]
df_x=df_x.set_index('Month')

df_x.plot(kind='area',stacked=False,color='green',figsize=(20,15))
plt.ylabel('MOM %')
plt.title('MOM % Loss ',size=25,color='maroon')
plt.show()

# Draw a bar chart comparing average return time by Category, in different Tier

plt.figure(figsize=(20,13))
sb.barplot(data=df,x='Category',y='return_delay',hue='Tier',errorbar=('ci',0),palette='magma',estimator='mean' )
plt.title('Tier vs Category Average Return ',size=25,color='maroon')
plt.legend(loc=1)
plt.show()

# Use a boxplot to examine ReturnDelay distribution by product.

plt.figure(figsize=(20,25))
sb.boxplot(data=df_rt,y='Product_Name',x='return_delay',palette='coolwarm')
plt.title('Productwise Return_Delay  ',size=25,color='indigo')
plt.show()

# Plot a violin plot of ReturnDelay by ReturnReason, in Return Risk

plt.figure(figsize=(15,13))
sb.violinplot(data=df_rt,x='ReturnReason',y='return_delay',hue='Return_Risk',split=True,palette='magma')
plt.title('Return Reason vs Return Delay , Riskwise  ',size=25,color='maroon')
plt.show()

# Create a stacked bar chart of returns count by City and Gender.

df_x=pd.crosstab(index=df['City'],columns=df['CustomerGender'])
df_x.plot(kind='barh',stacked=True,figsize=(20,60),colormap='plasma')
plt.ylabel('City')
plt.title('City vs Gender Total Return',size=25,color='purple')
plt.legend(loc=1)
plt.show()

# Generate a bar chart of Statewise-wise Loss in different Quarter


df_x=pd.crosstab(index=df['State'],columns=df['Quarter'],values=df['Sales'],aggfunc='sum')
df_x.plot(kind='barh',stacked=True,figsize=(20,40),colormap='magma')
plt.ylabel('State')
plt.xlabel('Loss')
plt.title('State vs Quarter Total Loss',size=25,color='indigo')
plt.legend(loc=1)
plt.show()

